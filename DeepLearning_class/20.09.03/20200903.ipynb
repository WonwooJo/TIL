{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['budget', 'genres', 'homepage', 'id', 'keywords', 'original_language',\n",
       "       'original_title', 'overview', 'popularity', 'production_companies',\n",
       "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
       "       'spoken_languages', 'status', 'tagline', 'title', 'vote_average',\n",
       "       'vote_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"tmdb_5000_movies.csv\")\n",
    "data.head()\n",
    "data.shape\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n필요로 하는 컬럼만 추출, 데이터 표준화/정규화,결측값 처리?\\n문자데이터(형태소분석, 불용어제거, 대/소문자 통일,...)\\nfeature engineering(특성공학, )\\n\\nxdata(수집데이터, 입력데이터, 독립변수) -> ydata(출력데이터, 종속변수)\\n국어, 영어, 수학, 언어능력(50점만점)   수능점수\\n80     90   100 ,  40   400점\\n         ...\\n100명 학생 점수 data를 수집\\n\\n파생변수 : 기존의 독립변수로부터 연산을 수행하여 만든 변수\\n\\nx변수들 -> 모델 -> y예측값(y hat)\\n90 100 95 -> ???예측\\n\\n타이타닉 data \\n승객명단          성별(파생)\\nMrs. 이름...        0\\nMr. 이름...           1\\nDr. ...\\n\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########데이터 전처리##########\n",
    "#추천시스템 동작 : 기존에 이미 시청한 영화의 제목을 입력 -> 영화와 비슷한 영화를 추천\n",
    "#                                                    컨텐츠기반추천\n",
    "data=data[['id','genres', 'vote_average','vote_count', 'popularity', \n",
    "      'title', 'keywords', 'overview']]\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "필요로 하는 컬럼만 추출, 데이터 표준화/정규화,결측값 처리?\n",
    "문자데이터(형태소분석, 불용어제거, 대/소문자 통일,...)\n",
    "feature engineering(특성공학, )\n",
    "\n",
    "xdata(수집데이터, 입력데이터, 독립변수) -> ydata(출력데이터, 종속변수)\n",
    "국어, 영어, 수학, 언어능력(50점만점)   수능점수\n",
    "80     90   100 ,  40   400점\n",
    "         ...\n",
    "100명 학생 점수 data를 수집\n",
    "\n",
    "파생변수 : 기존의 독립변수로부터 연산을 수행하여 만든 변수\n",
    "\n",
    "x변수들 -> 모델 -> y예측값(y hat)\n",
    "90 100 95 -> ???예측\n",
    "\n",
    "타이타닉 data \n",
    "승객명단          성별(파생)\n",
    "Mrs. 이름...        0\n",
    "Mr. 이름...           1\n",
    "Dr. ...\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['vote_count'].quantile(0.9)#1838\n",
    "#상위 10% 지점에 해당되는 vote_count 컬럼 값이 1838 이다.\n",
    "tmp_m=data['vote_count'].quantile(0.89)#1683\n",
    "data['vote_count']>=tmp_m\n",
    "tmp_data=data.copy()[data['vote_count']>=tmp_m]\n",
    "tmp_data.shape\n",
    "\n",
    "m=data['vote_count'].quantile(0.9)\n",
    "data=data[data['vote_count']>=m]\n",
    "#vote_count값에 대해 대략 500등 안에 들어가는 데이터를 추출\n",
    "\n",
    "#data.info()\n",
    "#수치데이터(연속형(점수,온도), 범주형(성별,혈액형,학점))\n",
    "#연속형 수치데이터 -> 구간 -> 범주화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>genres</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>popularity</th>\n",
       "      <th>title</th>\n",
       "      <th>keywords</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206647</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4466</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49026</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9106</td>\n",
       "      <td>112.312950</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>[{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...</td>\n",
       "      <td>Following the death of District Attorney Harve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49529</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2124</td>\n",
       "      <td>43.926995</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>[{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...</td>\n",
       "      <td>John Carter is a war-weary, former military ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                             genres  vote_average  \\\n",
       "0   19995  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...           7.2   \n",
       "1     285  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...           6.9   \n",
       "2  206647  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...           6.3   \n",
       "3   49026  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...           7.6   \n",
       "4   49529  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...           6.1   \n",
       "\n",
       "   vote_count  popularity                                     title  \\\n",
       "0       11800  150.437577                                    Avatar   \n",
       "1        4500  139.082615  Pirates of the Caribbean: At World's End   \n",
       "2        4466  107.376788                                   Spectre   \n",
       "3        9106  112.312950                     The Dark Knight Rises   \n",
       "4        2124   43.926995                               John Carter   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...   \n",
       "1  [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...   \n",
       "2  [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...   \n",
       "3  [{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...   \n",
       "4  [{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...   \n",
       "\n",
       "                                            overview  \n",
       "0  In the 22nd century, a paraplegic Marine is di...  \n",
       "1  Captain Barbossa, long believed to be dead, ha...  \n",
       "2  A cryptic message from Bond’s past sends him o...  \n",
       "3  Following the death of District Attorney Harve...  \n",
       "4  John Carter is a war-weary, former military ca...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1838.4000000000015"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=data['vote_average'].mean()\n",
    "c #6.96\n",
    "m #1838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(WR) = (v ÷ (v+m)) × R + (m ÷ (v+m)) × C\n",
    "def weighted_rating(x, m=m, c=c):\n",
    "    v=x['vote_count']\n",
    "    R=x['vote_average']\n",
    "    return (v/(v+m)*R) + (m/(m+v)*c)\n",
    "    \n",
    "data['score']=data.apply(weighted_rating, axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>[{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>[{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              genres  \\\n",
       "0  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "1  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "2  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "3  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
       "4  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "\n",
       "                                            keywords  \n",
       "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...  \n",
       "1  [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...  \n",
       "2  [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...  \n",
       "3  [{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...  \n",
       "4  [{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "data[['genres', 'keywords']].head()\n",
    "#리스트 내부에 딕셔너리 구조로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['genres'].apply(ast.literal_eval)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1,2,3,4,5]'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eval()\n",
    "listStr='[1,2,3,4,5]'\n",
    "listStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "listData=ast.literal_eval(listStr)\n",
    "listData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['genres']=data['genres'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['keywords']=data['keywords'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 12, 'nam...</td>\n",
       "      <td>[{'id': 1463, 'name': 'culture clash'}, {'id':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>[{'id': 270, 'name': 'ocean'}, {'id': 726, 'na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 12, 'nam...</td>\n",
       "      <td>[{'id': 470, 'name': 'spy'}, {'id': 818, 'name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 80, 'nam...</td>\n",
       "      <td>[{'id': 849, 'name': 'dc comics'}, {'id': 853,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'id': 28, 'name': 'Action'}, {'id': 12, 'nam...</td>\n",
       "      <td>[{'id': 818, 'name': 'based on novel'}, {'id':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4291</th>\n",
       "      <td>[{'id': 27, 'name': 'Horror'}, {'id': 9648, 'n...</td>\n",
       "      <td>[{'id': 1366, 'name': 'shotgun'}, {'id': 13000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>[{'id': 80, 'name': 'Crime'}, {'id': 53, 'name...</td>\n",
       "      <td>[{'id': 2052, 'name': 'traitor'}, {'id': 6099,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4302</th>\n",
       "      <td>[{'id': 37, 'name': 'Western'}]</td>\n",
       "      <td>[{'id': 801, 'name': 'bounty hunter'}, {'id': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4337</th>\n",
       "      <td>[{'id': 80, 'name': 'Crime'}, {'id': 18, 'name...</td>\n",
       "      <td>[{'id': 422, 'name': 'vietnam veteran'}, {'id'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4602</th>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
       "      <td>[{'id': 934, 'name': 'judge'}, {'id': 1417, 'n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>481 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 genres  \\\n",
       "0     [{'id': 28, 'name': 'Action'}, {'id': 12, 'nam...   \n",
       "1     [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2     [{'id': 28, 'name': 'Action'}, {'id': 12, 'nam...   \n",
       "3     [{'id': 28, 'name': 'Action'}, {'id': 80, 'nam...   \n",
       "4     [{'id': 28, 'name': 'Action'}, {'id': 12, 'nam...   \n",
       "...                                                 ...   \n",
       "4291  [{'id': 27, 'name': 'Horror'}, {'id': 9648, 'n...   \n",
       "4300  [{'id': 80, 'name': 'Crime'}, {'id': 53, 'name...   \n",
       "4302                    [{'id': 37, 'name': 'Western'}]   \n",
       "4337  [{'id': 80, 'name': 'Crime'}, {'id': 18, 'name...   \n",
       "4602                      [{'id': 18, 'name': 'Drama'}]   \n",
       "\n",
       "                                               keywords  \n",
       "0     [{'id': 1463, 'name': 'culture clash'}, {'id':...  \n",
       "1     [{'id': 270, 'name': 'ocean'}, {'id': 726, 'na...  \n",
       "2     [{'id': 470, 'name': 'spy'}, {'id': 818, 'name...  \n",
       "3     [{'id': 849, 'name': 'dc comics'}, {'id': 853,...  \n",
       "4     [{'id': 818, 'name': 'based on novel'}, {'id':...  \n",
       "...                                                 ...  \n",
       "4291  [{'id': 1366, 'name': 'shotgun'}, {'id': 13000...  \n",
       "4300  [{'id': 2052, 'name': 'traitor'}, {'id': 6099,...  \n",
       "4302  [{'id': 801, 'name': 'bounty hunter'}, {'id': ...  \n",
       "4337  [{'id': 422, 'name': 'vietnam veteran'}, {'id'...  \n",
       "4602  [{'id': 934, 'name': 'judge'}, {'id': 1417, 'n...  \n",
       "\n",
       "[481 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['genres', 'keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 270, 'name': 'ocean'},\n",
       " {'id': 726, 'name': 'drug abuse'},\n",
       " {'id': 911, 'name': 'exotic island'},\n",
       " {'id': 1319, 'name': 'east india trading company'},\n",
       " {'id': 2038, 'name': \"love of one's life\"},\n",
       " {'id': 2052, 'name': 'traitor'},\n",
       " {'id': 2580, 'name': 'shipwreck'},\n",
       " {'id': 2660, 'name': 'strong woman'},\n",
       " {'id': 3799, 'name': 'ship'},\n",
       " {'id': 5740, 'name': 'alliance'},\n",
       " {'id': 5941, 'name': 'calypso'},\n",
       " {'id': 6155, 'name': 'afterlife'},\n",
       " {'id': 6211, 'name': 'fighter'},\n",
       " {'id': 12988, 'name': 'pirate'},\n",
       " {'id': 157186, 'name': 'swashbuckler'},\n",
       " {'id': 179430, 'name': 'aftercreditsstinger'}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0]['genres']\n",
    "# 모든 데이터의 장르 이름을 출력\n",
    "#     genres\n",
    "# 0  Action\n",
    "#    Adventure\n",
    "#      ...\n",
    "# 1  Adventure\n",
    "#     ...\n",
    "\n",
    "data.iloc[1]['keywords']\n",
    "#apply함수 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 28, 'name': 'Action'},\n",
       " {'id': 12, 'name': 'Adventure'},\n",
       " {'id': 14, 'name': 'Fantasy'},\n",
       " {'id': 878, 'name': 'Science Fiction'}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0]['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['genres']=data['genres'].apply(lambda x: [d['name'] for d in x]).\n",
    "apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['keywords']=data['keywords'].apply(lambda x: [d['name'] for d in x]).\n",
    "apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)\n",
    "data.to_csv(\"pre_tmdb_5000_movies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########컨텐츠(성별,장르,토픽,예산,....) 기반 필터링 -> 추천시스템#########\n",
    "#우리는 장르를 이용해서 추천시스템 만들 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#장르(문자열)->숫자로 변환 -> 벡터화 작업\n",
    "from sklearn.feature_extraction.text import *\n",
    "#scikit->sk\n",
    "#scikit-learn.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Action Adventure Fantasy Science Fiction\n",
       "1                       Adventure Fantasy Action\n",
       "2                         Action Adventure Crime\n",
       "3                    Action Crime Drama Thriller\n",
       "4               Action Adventure Science Fiction\n",
       "                          ...                   \n",
       "4291                        Horror Mystery Crime\n",
       "4300                              Crime Thriller\n",
       "4302                                     Western\n",
       "4337                                 Crime Drama\n",
       "4602                                       Drama\n",
       "Name: genres, Length: 481, dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.genres #벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. fit_transform함수를 이용한 장르 벡터화\n",
    "data.head(2)\n",
    "#장르를 벡터화\n",
    "count_vector=CountVectorizer(ngram_range=(1,3))\n",
    "c_vector_genres=count_vector.fit_transform(data['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(481, 364)\n"
     ]
    }
   ],
   "source": [
    "print(c_vector_genres.toarray())\n",
    "print(c_vector_genres.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(ngram_range=(1, 3))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. fit & transform함수를 이용한 장르 벡터화\n",
    "count_vector=CountVectorizer(ngram_range=(1,3))\n",
    "count_vector.fit(data['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['action',\n",
       " 'action adventure',\n",
       " 'action adventure animation',\n",
       " 'action adventure comedy',\n",
       " 'action adventure crime',\n",
       " 'action adventure fantasy',\n",
       " 'action adventure science',\n",
       " 'action adventure thriller',\n",
       " 'action adventure war',\n",
       " 'action adventure western',\n",
       " 'action comedy',\n",
       " 'action comedy crime',\n",
       " 'action comedy drama',\n",
       " 'action comedy family',\n",
       " 'action comedy science',\n",
       " 'action crime',\n",
       " 'action crime drama',\n",
       " 'action crime mystery',\n",
       " 'action crime thriller',\n",
       " 'action drama',\n",
       " 'action drama adventure',\n",
       " 'action drama fantasy',\n",
       " 'action drama history',\n",
       " 'action drama horror',\n",
       " 'action drama mystery',\n",
       " 'action drama science',\n",
       " 'action drama thriller',\n",
       " 'action family',\n",
       " 'action family fantasy',\n",
       " 'action family romance',\n",
       " 'action fantasy',\n",
       " 'action fantasy comedy',\n",
       " 'action horror',\n",
       " 'action mystery',\n",
       " 'action mystery science',\n",
       " 'action mystery thriller',\n",
       " 'action romance',\n",
       " 'action science',\n",
       " 'action science fiction',\n",
       " 'action thriller',\n",
       " 'action thriller adventure',\n",
       " 'action thriller crime',\n",
       " 'action thriller fantasy',\n",
       " 'action thriller mystery',\n",
       " 'action thriller science',\n",
       " 'action thriller war',\n",
       " 'action war',\n",
       " 'action war history',\n",
       " 'adventure',\n",
       " 'adventure action',\n",
       " 'adventure action crime',\n",
       " 'adventure action family',\n",
       " 'adventure action fantasy',\n",
       " 'adventure action science',\n",
       " 'adventure action thriller',\n",
       " 'adventure animation',\n",
       " 'adventure animation comedy',\n",
       " 'adventure animation family',\n",
       " 'adventure animation mystery',\n",
       " 'adventure comedy',\n",
       " 'adventure comedy crime',\n",
       " 'adventure comedy drama',\n",
       " 'adventure comedy family',\n",
       " 'adventure comedy fantasy',\n",
       " 'adventure comedy science',\n",
       " 'adventure crime',\n",
       " 'adventure crime fantasy',\n",
       " 'adventure crime mystery',\n",
       " 'adventure drama',\n",
       " 'adventure drama action',\n",
       " 'adventure drama family',\n",
       " 'adventure drama fantasy',\n",
       " 'adventure drama science',\n",
       " 'adventure drama thriller',\n",
       " 'adventure drama war',\n",
       " 'adventure family',\n",
       " 'adventure family animation',\n",
       " 'adventure family fantasy',\n",
       " 'adventure family mystery',\n",
       " 'adventure fantasy',\n",
       " 'adventure fantasy action',\n",
       " 'adventure fantasy animation',\n",
       " 'adventure fantasy comedy',\n",
       " 'adventure fantasy drama',\n",
       " 'adventure fantasy family',\n",
       " 'adventure fantasy romance',\n",
       " 'adventure fantasy science',\n",
       " 'adventure mystery',\n",
       " 'adventure science',\n",
       " 'adventure science fiction',\n",
       " 'adventure thriller',\n",
       " 'adventure thriller science',\n",
       " 'adventure war',\n",
       " 'adventure western',\n",
       " 'animation',\n",
       " 'animation action',\n",
       " 'animation action comedy',\n",
       " 'animation adventure',\n",
       " 'animation adventure comedy',\n",
       " 'animation adventure family',\n",
       " 'animation comedy',\n",
       " 'animation comedy adventure',\n",
       " 'animation comedy family',\n",
       " 'animation comedy fantasy',\n",
       " 'animation drama',\n",
       " 'animation family',\n",
       " 'animation family adventure',\n",
       " 'animation family comedy',\n",
       " 'animation music',\n",
       " 'animation mystery',\n",
       " 'comedy',\n",
       " 'comedy action',\n",
       " 'comedy action adventure',\n",
       " 'comedy adventure',\n",
       " 'comedy adventure family',\n",
       " 'comedy adventure fantasy',\n",
       " 'comedy animation',\n",
       " 'comedy animation family',\n",
       " 'comedy crime',\n",
       " 'comedy crime drama',\n",
       " 'comedy crime fantasy',\n",
       " 'comedy crime mystery',\n",
       " 'comedy crime thriller',\n",
       " 'comedy drama',\n",
       " 'comedy drama fantasy',\n",
       " 'comedy drama romance',\n",
       " 'comedy drama science',\n",
       " 'comedy drama thriller',\n",
       " 'comedy family',\n",
       " 'comedy family action',\n",
       " 'comedy family adventure',\n",
       " 'comedy family fantasy',\n",
       " 'comedy family science',\n",
       " 'comedy family western',\n",
       " 'comedy fantasy',\n",
       " 'comedy fantasy family',\n",
       " 'comedy horror',\n",
       " 'comedy music',\n",
       " 'comedy music romance',\n",
       " 'comedy romance',\n",
       " 'comedy romance drama',\n",
       " 'comedy science',\n",
       " 'comedy science fiction',\n",
       " 'crime',\n",
       " 'crime action',\n",
       " 'crime action comedy',\n",
       " 'crime action science',\n",
       " 'crime comedy',\n",
       " 'crime comedy action',\n",
       " 'crime drama',\n",
       " 'crime drama comedy',\n",
       " 'crime drama mystery',\n",
       " 'crime drama thriller',\n",
       " 'crime fantasy',\n",
       " 'crime fantasy science',\n",
       " 'crime mystery',\n",
       " 'crime mystery drama',\n",
       " 'crime mystery thriller',\n",
       " 'crime thriller',\n",
       " 'drama',\n",
       " 'drama action',\n",
       " 'drama action crime',\n",
       " 'drama action thriller',\n",
       " 'drama action war',\n",
       " 'drama adventure',\n",
       " 'drama adventure science',\n",
       " 'drama adventure thriller',\n",
       " 'drama comedy',\n",
       " 'drama comedy animation',\n",
       " 'drama comedy romance',\n",
       " 'drama crime',\n",
       " 'drama crime thriller',\n",
       " 'drama family',\n",
       " 'drama fantasy',\n",
       " 'drama fantasy romance',\n",
       " 'drama fantasy war',\n",
       " 'drama history',\n",
       " 'drama history crime',\n",
       " 'drama history war',\n",
       " 'drama horror',\n",
       " 'drama horror action',\n",
       " 'drama horror science',\n",
       " 'drama horror thriller',\n",
       " 'drama music',\n",
       " 'drama music romance',\n",
       " 'drama mystery',\n",
       " 'drama mystery romance',\n",
       " 'drama mystery thriller',\n",
       " 'drama mystery western',\n",
       " 'drama romance',\n",
       " 'drama romance thriller',\n",
       " 'drama science',\n",
       " 'drama science fiction',\n",
       " 'drama thriller',\n",
       " 'drama thriller action',\n",
       " 'drama thriller crime',\n",
       " 'drama thriller history',\n",
       " 'drama thriller mystery',\n",
       " 'drama thriller war',\n",
       " 'drama war',\n",
       " 'drama western',\n",
       " 'family',\n",
       " 'family action',\n",
       " 'family action fantasy',\n",
       " 'family adventure',\n",
       " 'family adventure comedy',\n",
       " 'family adventure crime',\n",
       " 'family adventure drama',\n",
       " 'family animation',\n",
       " 'family animation action',\n",
       " 'family animation adventure',\n",
       " 'family animation comedy',\n",
       " 'family animation drama',\n",
       " 'family comedy',\n",
       " 'family comedy adventure',\n",
       " 'family drama',\n",
       " 'family fantasy',\n",
       " 'family fantasy adventure',\n",
       " 'family mystery',\n",
       " 'family mystery science',\n",
       " 'family romance',\n",
       " 'family science',\n",
       " 'family science fiction',\n",
       " 'family western',\n",
       " 'family western adventure',\n",
       " 'fantasy',\n",
       " 'fantasy action',\n",
       " 'fantasy action adventure',\n",
       " 'fantasy action comedy',\n",
       " 'fantasy action horror',\n",
       " 'fantasy action romance',\n",
       " 'fantasy action science',\n",
       " 'fantasy action thriller',\n",
       " 'fantasy adventure',\n",
       " 'fantasy adventure action',\n",
       " 'fantasy adventure animation',\n",
       " 'fantasy adventure family',\n",
       " 'fantasy animation',\n",
       " 'fantasy animation adventure',\n",
       " 'fantasy animation family',\n",
       " 'fantasy animation music',\n",
       " 'fantasy comedy',\n",
       " 'fantasy comedy romance',\n",
       " 'fantasy drama',\n",
       " 'fantasy drama comedy',\n",
       " 'fantasy drama crime',\n",
       " 'fantasy drama mystery',\n",
       " 'fantasy drama romance',\n",
       " 'fantasy drama thriller',\n",
       " 'fantasy drama war',\n",
       " 'fantasy family',\n",
       " 'fantasy family drama',\n",
       " 'fantasy family mystery',\n",
       " 'fantasy horror',\n",
       " 'fantasy horror action',\n",
       " 'fantasy romance',\n",
       " 'fantasy science',\n",
       " 'fantasy science fiction',\n",
       " 'fantasy war',\n",
       " 'fiction',\n",
       " 'fiction action',\n",
       " 'fiction action adventure',\n",
       " 'fiction action drama',\n",
       " 'fiction action thriller',\n",
       " 'fiction adventure',\n",
       " 'fiction adventure action',\n",
       " 'fiction adventure family',\n",
       " 'fiction adventure fantasy',\n",
       " 'fiction adventure mystery',\n",
       " 'fiction adventure thriller',\n",
       " 'fiction drama',\n",
       " 'fiction drama mystery',\n",
       " 'fiction drama romance',\n",
       " 'fiction drama thriller',\n",
       " 'fiction family',\n",
       " 'fiction fantasy',\n",
       " 'fiction fantasy action',\n",
       " 'fiction horror',\n",
       " 'fiction horror thriller',\n",
       " 'fiction mystery',\n",
       " 'fiction mystery adventure',\n",
       " 'fiction thriller',\n",
       " 'fiction thriller drama',\n",
       " 'history',\n",
       " 'history crime',\n",
       " 'history drama',\n",
       " 'history drama thriller',\n",
       " 'history war',\n",
       " 'horror',\n",
       " 'horror action',\n",
       " 'horror action drama',\n",
       " 'horror action science',\n",
       " 'horror action thriller',\n",
       " 'horror comedy',\n",
       " 'horror comedy romance',\n",
       " 'horror mystery',\n",
       " 'horror mystery crime',\n",
       " 'horror science',\n",
       " 'horror science fiction',\n",
       " 'horror thriller',\n",
       " 'horror thriller adventure',\n",
       " 'music',\n",
       " 'music romance',\n",
       " 'mystery',\n",
       " 'mystery action',\n",
       " 'mystery adventure',\n",
       " 'mystery adventure crime',\n",
       " 'mystery crime',\n",
       " 'mystery drama',\n",
       " 'mystery romance',\n",
       " 'mystery science',\n",
       " 'mystery science fiction',\n",
       " 'mystery thriller',\n",
       " 'mystery thriller drama',\n",
       " 'mystery western',\n",
       " 'romance',\n",
       " 'romance comedy',\n",
       " 'romance comedy crime',\n",
       " 'romance drama',\n",
       " 'romance fantasy',\n",
       " 'romance fantasy animation',\n",
       " 'romance fantasy drama',\n",
       " 'romance fantasy family',\n",
       " 'romance science',\n",
       " 'romance science fiction',\n",
       " 'romance thriller',\n",
       " 'science',\n",
       " 'science fiction',\n",
       " 'science fiction action',\n",
       " 'science fiction adventure',\n",
       " 'science fiction drama',\n",
       " 'science fiction family',\n",
       " 'science fiction fantasy',\n",
       " 'science fiction horror',\n",
       " 'science fiction mystery',\n",
       " 'science fiction thriller',\n",
       " 'thriller',\n",
       " 'thriller action',\n",
       " 'thriller action adventure',\n",
       " 'thriller action crime',\n",
       " 'thriller action drama',\n",
       " 'thriller adventure',\n",
       " 'thriller adventure action',\n",
       " 'thriller crime',\n",
       " 'thriller crime mystery',\n",
       " 'thriller drama',\n",
       " 'thriller drama crime',\n",
       " 'thriller fantasy',\n",
       " 'thriller history',\n",
       " 'thriller mystery',\n",
       " 'thriller mystery action',\n",
       " 'thriller mystery romance',\n",
       " 'thriller science',\n",
       " 'thriller science fiction',\n",
       " 'thriller war',\n",
       " 'war',\n",
       " 'war action',\n",
       " 'war drama',\n",
       " 'war drama action',\n",
       " 'war history',\n",
       " 'western',\n",
       " 'western adventure',\n",
       " 'western drama',\n",
       " 'western drama adventure']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vector.get_feature_names())\n",
    "count_vector.get_feature_names()\n",
    "#          <-----------------------364---------------------------->\n",
    "#          'action'   'action adventure' ... 'western drama adventure'\n",
    "# 람보         1              1       0      0 ...        1\n",
    "# ...\n",
    "# 코만도       1              0       1      0            1\n",
    "# ...\n",
    "# 481편\n",
    "\n",
    "# 모든 각각의 영화들은 364차원 공간에 점(point)으로 표시\n",
    "# 점의 총 개수? 481개\n",
    "\n",
    "\n",
    "#          발   손    공부  폭탄 여행\n",
    "# 람보    1     2     0     3       0\n",
    "# 코만도 1     2     0     3       0\n",
    "# 토지    0    1      1     0       2\n",
    "\n",
    "# 람보를 시청한 관객에게 어떤 영화를 추천?\n",
    "# cos(람보,코만도)=14 / 14 = 1(똑같다)\n",
    "# cos(람보,토지) = 2 / 9.xx=0.2xxx\n",
    "# cos(람보,코만도)  >  cos(람보,토지) \n",
    "# => 람보를 본 사람에게 코만도를 추천하자!!!\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "c_vector_genres.toarray().shape\n",
    "#(481, 364)\n",
    "#\n",
    "c_vector_genres.toarray()[3]\n",
    "\n",
    "#c_vector_genres.toarray()에서 481개 모든 영화들에 대한 쌍을 구성했을때\n",
    "#가장 코사인유사도가 큰 값을 출력(인덱스도 함께)\n",
    "#ex) \n",
    "print(c_vector_genres.toarray()[0]) #d1\n",
    "print(c_vector_genres.toarray()[1]) #d2\n",
    "cos(d1,d2)=d1*d2 / d1요소값 제곱합에 대한 제곱근 * d2요소값 제곱합에 대한 제곱근\n",
    "...\n",
    "cos(d1,d481)=d1*d481 / d1요소값 제곱합에 대한 제곱근 * d481요소값 제곱합에 대한 제곱근\n",
    "=>\n",
    "최대값에 해당되는 인덱스? 그때의 코사인 유사도?\n",
    "data[최대값에 해당되는 인덱스][title] 출력 (추천영화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Action Adventure Fantasy Science Fiction'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0].genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adventure Fantasy Action'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[1].genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bow란 (Bag of Words, 단어가방): 문서를 구성하는 모든 단어들에 대해 표시하는 방법\n",
    "\n",
    "문서1:나는 대한민국 사람\n",
    "문서2:나는 미국 사람\n",
    "문서3:나는 중국 사람\n",
    "\n",
    "코퍼스(corpus, 말뭉치) : {나는, 대한민국, 미국, 중국, 사람}\n",
    "코퍼스 : 단어(도메인) 사전\n",
    "\n",
    "토지소설 -> 원고 -> 토지 코퍼스:{토지 소설에 등장하는 단어들}\n",
    "태백산맥 소설 -> 원고 -> 태백산맥 단어들 중에는 토지 코퍼스에 있는 단어도 있지만,\n",
    "없는 단어도 있을 것이다(예, '지리산' 단어는 토지에는 등장하지 않음 -> OOV라고 함)\n",
    "\n",
    "\n",
    "\n",
    "Bow: 전체 문서{d1,...,dn}를 구성하는 단어장(vocabulary, {t1,t2,...,tm})를 만든 다음,\n",
    "각각의 문서(n개)에 대해 단어장에 있는 각각의 단어가 문서 내에 포함되어 있는지,\n",
    "되어 있지 않은지를 표시하는 방법\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 4.]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "#DictVectorizer:단어의 빈도 정보가 담긴 딕셔너리로부터  BOW 벡터를 생성\n",
    "v=DictVectorizer(sparse=False)\n",
    "D=[{'A':1, 'B':2},{'B':3,'C':1}]#단어의 빈도 정보가 담긴 딕셔너리\n",
    "#1번 문서 : {'A':1, 'B':2}, 2번 문서 : {'B':3,'C':1}\n",
    "x=v.fit_transform(D)\n",
    "x #bow 출력\n",
    "#sparse <-> dense\n",
    "v.feature_names_\n",
    "v.transform({'C':4, 'D':2})\n",
    "#{'C':4, 'D':2}딕셔너리를 v변수에 저장된 벡터화 방식으로 변환(bow)해라\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 9, 'is': 3, 'the': 7, 'first': 2, 'document': 1, 'second': 6, 'and': 0, 'third': 8, 'one': 5, 'last': 4}\n",
      "[[0 1 1 1 0 0 0 1 0 1]\n",
      " [0 1 0 1 0 0 2 1 0 1]\n",
      " [1 0 0 0 0 1 0 1 1 0]\n",
      " [0 1 0 0 1 0 0 1 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0, 0, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CountVectorizer\n",
    "#문서 -> 단어 토큰 리스트 -> 단어 출현 빈도 -> bow  벡터로 변환\n",
    "corpus=[ #해당 도메인에 대한 관련 문서들의 집합\n",
    "    'This is the first document',\n",
    "    'This is the second second document',\n",
    "    'And the third one',\n",
    "    'The last document'\n",
    "]\n",
    "cv=CountVectorizer()\n",
    "cv.fit(corpus)\n",
    "print(cv.vocabulary_) #0~9번까지 총 10개의 단어로 구성됨\n",
    "print(cv.transform(corpus).toarray())\n",
    "#  0 1 2 3 4 5 6 7 8 9\n",
    "# [0 1 1 1 0 0 0 1 0 1]\n",
    "# 'This is the first document'\n",
    "\n",
    "#새로운 문서를 입력받아 bow생성\n",
    "cv.transform(['Something completely new']).toarray()\n",
    "cv.transform(['This is the third doc']).toarray()\n",
    "#3,7,8,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[ #해당 도메인에 대한 관련 문서들의 집합\n",
    "    'This is the first document',\n",
    "    'This is the second second document',\n",
    "    'And the third one',\n",
    "    'The last document'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 7, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 6, 'one': 4, 'last': 3}\n",
      "[[0 1 1 0 0 0 0 1]\n",
      " [0 1 0 0 0 2 0 1]\n",
      " [1 0 0 0 1 0 1 0]\n",
      " [0 1 0 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(stop_words=['is','the'])\n",
    "#stop_words:불용어()\n",
    "cv.fit(corpus)\n",
    "print(cv.vocabulary_)\n",
    "print(cv.transform(corpus).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'document': 0, 'second': 1}\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer(stop_words='english')\n",
    "cv.fit(corpus)\n",
    "print(cv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'a',\n",
       "           'about',\n",
       "           'above',\n",
       "           'across',\n",
       "           'after',\n",
       "           'afterwards',\n",
       "           'again',\n",
       "           'against',\n",
       "           'all',\n",
       "           'almost',\n",
       "           'alone',\n",
       "           'along',\n",
       "           'already',\n",
       "           'also',\n",
       "           'although',\n",
       "           'always',\n",
       "           'am',\n",
       "           'among',\n",
       "           'amongst',\n",
       "           'amoungst',\n",
       "           'amount',\n",
       "           'an',\n",
       "           'and',\n",
       "           'another',\n",
       "           'any',\n",
       "           'anyhow',\n",
       "           'anyone',\n",
       "           'anything',\n",
       "           'anyway',\n",
       "           'anywhere',\n",
       "           'are',\n",
       "           'around',\n",
       "           'as',\n",
       "           'at',\n",
       "           'back',\n",
       "           'be',\n",
       "           'became',\n",
       "           'because',\n",
       "           'become',\n",
       "           'becomes',\n",
       "           'becoming',\n",
       "           'been',\n",
       "           'before',\n",
       "           'beforehand',\n",
       "           'behind',\n",
       "           'being',\n",
       "           'below',\n",
       "           'beside',\n",
       "           'besides',\n",
       "           'between',\n",
       "           'beyond',\n",
       "           'bill',\n",
       "           'both',\n",
       "           'bottom',\n",
       "           'but',\n",
       "           'by',\n",
       "           'call',\n",
       "           'can',\n",
       "           'cannot',\n",
       "           'cant',\n",
       "           'co',\n",
       "           'con',\n",
       "           'could',\n",
       "           'couldnt',\n",
       "           'cry',\n",
       "           'de',\n",
       "           'describe',\n",
       "           'detail',\n",
       "           'do',\n",
       "           'done',\n",
       "           'down',\n",
       "           'due',\n",
       "           'during',\n",
       "           'each',\n",
       "           'eg',\n",
       "           'eight',\n",
       "           'either',\n",
       "           'eleven',\n",
       "           'else',\n",
       "           'elsewhere',\n",
       "           'empty',\n",
       "           'enough',\n",
       "           'etc',\n",
       "           'even',\n",
       "           'ever',\n",
       "           'every',\n",
       "           'everyone',\n",
       "           'everything',\n",
       "           'everywhere',\n",
       "           'except',\n",
       "           'few',\n",
       "           'fifteen',\n",
       "           'fifty',\n",
       "           'fill',\n",
       "           'find',\n",
       "           'fire',\n",
       "           'first',\n",
       "           'five',\n",
       "           'for',\n",
       "           'former',\n",
       "           'formerly',\n",
       "           'forty',\n",
       "           'found',\n",
       "           'four',\n",
       "           'from',\n",
       "           'front',\n",
       "           'full',\n",
       "           'further',\n",
       "           'get',\n",
       "           'give',\n",
       "           'go',\n",
       "           'had',\n",
       "           'has',\n",
       "           'hasnt',\n",
       "           'have',\n",
       "           'he',\n",
       "           'hence',\n",
       "           'her',\n",
       "           'here',\n",
       "           'hereafter',\n",
       "           'hereby',\n",
       "           'herein',\n",
       "           'hereupon',\n",
       "           'hers',\n",
       "           'herself',\n",
       "           'him',\n",
       "           'himself',\n",
       "           'his',\n",
       "           'how',\n",
       "           'however',\n",
       "           'hundred',\n",
       "           'i',\n",
       "           'ie',\n",
       "           'if',\n",
       "           'in',\n",
       "           'inc',\n",
       "           'indeed',\n",
       "           'interest',\n",
       "           'into',\n",
       "           'is',\n",
       "           'it',\n",
       "           'its',\n",
       "           'itself',\n",
       "           'keep',\n",
       "           'last',\n",
       "           'latter',\n",
       "           'latterly',\n",
       "           'least',\n",
       "           'less',\n",
       "           'ltd',\n",
       "           'made',\n",
       "           'many',\n",
       "           'may',\n",
       "           'me',\n",
       "           'meanwhile',\n",
       "           'might',\n",
       "           'mill',\n",
       "           'mine',\n",
       "           'more',\n",
       "           'moreover',\n",
       "           'most',\n",
       "           'mostly',\n",
       "           'move',\n",
       "           'much',\n",
       "           'must',\n",
       "           'my',\n",
       "           'myself',\n",
       "           'name',\n",
       "           'namely',\n",
       "           'neither',\n",
       "           'never',\n",
       "           'nevertheless',\n",
       "           'next',\n",
       "           'nine',\n",
       "           'no',\n",
       "           'nobody',\n",
       "           'none',\n",
       "           'noone',\n",
       "           'nor',\n",
       "           'not',\n",
       "           'nothing',\n",
       "           'now',\n",
       "           'nowhere',\n",
       "           'of',\n",
       "           'off',\n",
       "           'often',\n",
       "           'on',\n",
       "           'once',\n",
       "           'one',\n",
       "           'only',\n",
       "           'onto',\n",
       "           'or',\n",
       "           'other',\n",
       "           'others',\n",
       "           'otherwise',\n",
       "           'our',\n",
       "           'ours',\n",
       "           'ourselves',\n",
       "           'out',\n",
       "           'over',\n",
       "           'own',\n",
       "           'part',\n",
       "           'per',\n",
       "           'perhaps',\n",
       "           'please',\n",
       "           'put',\n",
       "           'rather',\n",
       "           're',\n",
       "           'same',\n",
       "           'see',\n",
       "           'seem',\n",
       "           'seemed',\n",
       "           'seeming',\n",
       "           'seems',\n",
       "           'serious',\n",
       "           'several',\n",
       "           'she',\n",
       "           'should',\n",
       "           'show',\n",
       "           'side',\n",
       "           'since',\n",
       "           'sincere',\n",
       "           'six',\n",
       "           'sixty',\n",
       "           'so',\n",
       "           'some',\n",
       "           'somehow',\n",
       "           'someone',\n",
       "           'something',\n",
       "           'sometime',\n",
       "           'sometimes',\n",
       "           'somewhere',\n",
       "           'still',\n",
       "           'such',\n",
       "           'system',\n",
       "           'take',\n",
       "           'ten',\n",
       "           'than',\n",
       "           'that',\n",
       "           'the',\n",
       "           'their',\n",
       "           'them',\n",
       "           'themselves',\n",
       "           'then',\n",
       "           'thence',\n",
       "           'there',\n",
       "           'thereafter',\n",
       "           'thereby',\n",
       "           'therefore',\n",
       "           'therein',\n",
       "           'thereupon',\n",
       "           'these',\n",
       "           'they',\n",
       "           'thick',\n",
       "           'thin',\n",
       "           'third',\n",
       "           'this',\n",
       "           'those',\n",
       "           'though',\n",
       "           'three',\n",
       "           'through',\n",
       "           'throughout',\n",
       "           'thru',\n",
       "           'thus',\n",
       "           'to',\n",
       "           'together',\n",
       "           'too',\n",
       "           'top',\n",
       "           'toward',\n",
       "           'towards',\n",
       "           'twelve',\n",
       "           'twenty',\n",
       "           'two',\n",
       "           'un',\n",
       "           'under',\n",
       "           'until',\n",
       "           'up',\n",
       "           'upon',\n",
       "           'us',\n",
       "           'very',\n",
       "           'via',\n",
       "           'was',\n",
       "           'we',\n",
       "           'well',\n",
       "           'were',\n",
       "           'what',\n",
       "           'whatever',\n",
       "           'when',\n",
       "           'whence',\n",
       "           'whenever',\n",
       "           'where',\n",
       "           'whereafter',\n",
       "           'whereas',\n",
       "           'whereby',\n",
       "           'wherein',\n",
       "           'whereupon',\n",
       "           'wherever',\n",
       "           'whether',\n",
       "           'which',\n",
       "           'while',\n",
       "           'whither',\n",
       "           'who',\n",
       "           'whoever',\n",
       "           'whole',\n",
       "           'whom',\n",
       "           'whose',\n",
       "           'why',\n",
       "           'will',\n",
       "           'with',\n",
       "           'within',\n",
       "           'without',\n",
       "           'would',\n",
       "           'yet',\n",
       "           'you',\n",
       "           'your',\n",
       "           'yours',\n",
       "           'yourself',\n",
       "           'yourselves'})"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t': 14,\n",
       " 'h': 6,\n",
       " 'i': 7,\n",
       " 's': 13,\n",
       " ' ': 0,\n",
       " 'e': 4,\n",
       " 'f': 5,\n",
       " 'r': 12,\n",
       " 'd': 3,\n",
       " 'o': 11,\n",
       " 'c': 2,\n",
       " 'u': 15,\n",
       " 'm': 9,\n",
       " 'n': 10,\n",
       " 'a': 1,\n",
       " 'l': 8}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(analyzer='char')\n",
    "cv.fit(corpus)\n",
    "cv.vocabulary_\n",
    "# corpus=[ #해당 도메인에 대한 관련 문서들의 집합\n",
    "#     '\n",
    "# This is the first document',\n",
    "#     'This is the second second document',\n",
    "#     'And the third one',\n",
    "#     'The last document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 2, 'the': 0, 'third': 1}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(token_pattern=\"t\\w+\")\n",
    "cv.fit(corpus)\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n-그램(Word2Vec):단어의 크기, \n",
    "#1(모노)-그램:토큰 하나만 단어, 2(바이)-그램:두개 토큰을 하나의 단어로 사용\n",
    "#This is the first document 문서를 2(바이)-그램으로 단어를 표현\n",
    "#This is, is the, the first, first document \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this is': 11,\n",
       " 'is the': 2,\n",
       " 'the first': 6,\n",
       " 'first document': 1,\n",
       " 'the second': 8,\n",
       " 'second second': 5,\n",
       " 'second document': 4,\n",
       " 'and the': 0,\n",
       " 'the third': 9,\n",
       " 'third one': 10,\n",
       " 'the last': 7,\n",
       " 'last document': 3}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(ngram_range=(2,2))\n",
    "cv.fit(corpus)\n",
    "cv.vocabulary_\n",
    "# This is the first document',\n",
    "#     'This is the second second document',\n",
    "#     'And the third one',\n",
    "#     'The last document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 20,\n",
       " 'is': 5,\n",
       " 'the': 13,\n",
       " 'first': 3,\n",
       " 'document': 2,\n",
       " 'this is': 21,\n",
       " 'is the': 6,\n",
       " 'the first': 14,\n",
       " 'first document': 4,\n",
       " 'second': 10,\n",
       " 'the second': 16,\n",
       " 'second second': 12,\n",
       " 'second document': 11,\n",
       " 'and': 0,\n",
       " 'third': 18,\n",
       " 'one': 9,\n",
       " 'and the': 1,\n",
       " 'the third': 17,\n",
       " 'third one': 19,\n",
       " 'last': 7,\n",
       " 'the last': 15,\n",
       " 'last document': 8}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,2))\n",
    "cv.fit(corpus)\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 3, 'the': 0, 'this the': 4, 'third': 2, 'the third': 1}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,2), token_pattern=\"t\\w+\")\n",
    "cv.fit(corpus)\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 3, 'is': 1, 'the': 2, 'document': 0}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus=['This is the first document',\n",
    "    'This is the second second second second second document',\n",
    "    'And the third one',\n",
    "    'The last document']\n",
    "\n",
    "#빈도수 기반 \n",
    "cv=CountVectorizer(min_df=2)\n",
    "cv.fit(corpus)\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1],\n",
       "       [1, 1, 1, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(corpus).toarray()\n",
    "#cv.transform(corpus).toarray().sum(axis=0) #[3, 2, 4, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eval함수:파이썬 내장함수\n",
    "eval(\"(5*2)/4\")\n",
    "eval(\"max([1,2,3])\")\n",
    "#eval함수는 보안에 취약 -> 보안에 강한 함수 필요성 -> literal_eval함수 등장\n",
    "s={'a':3,'b':5}\n",
    "s['a']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2=\"{'a':3,'b':5}\"\n",
    "ast.literal_eval(s2)['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string: <_ast.BinOp object at 0x000001824D0FF0D0>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-48f61609d7f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"10*2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"10*2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#literal_eval함수는 파이썬 기본 자료형에 대해서만 지원(매우 엄격)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#간단한 수식등은 eval 함수 사용\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ast.py\u001b[0m in \u001b[0;36mliteral_eval\u001b[1;34m(node_or_string)\u001b[0m\n\u001b[0;32m     97\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ast.py\u001b[0m in \u001b[0;36m_convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     96\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mleft\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ast.py\u001b[0m in \u001b[0;36m_convert_signed_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0moperand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ast.py\u001b[0m in \u001b[0;36m_convert_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[0m_raise_malformed_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_convert_signed_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ast.py\u001b[0m in \u001b[0;36m_raise_malformed_node\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mnode_or_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode_or_string\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_raise_malformed_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'malformed node or string: {node!r}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_convert_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConstant\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: malformed node or string: <_ast.BinOp object at 0x000001824D0FF0D0>"
     ]
    }
   ],
   "source": [
    "# eval(\"10*2\")\n",
    "# ast.literal_eval(\"10*2\")\n",
    "#literal_eval함수는 파이썬 기본 자료형에 대해서만 지원(매우 엄격)\n",
    "#간단한 수식등은 eval 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
