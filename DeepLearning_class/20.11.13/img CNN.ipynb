{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "gray_scale = 255\n",
    "x_train /= gray_scale\n",
    "x_test /= gray_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)), # 데이터 차원 변경\n",
    "#    Dense(256, activation='relu'), # 첫번째 히든 레이어 (h1)\n",
    "    Dense(128, activation='relu'), # 두번째 히든 레이어 (h2)\n",
    "#    Dropout(0.1), # 두번째 히든 레이어(h2)에 드랍아웃(10%) 적용 최종적으로 오버피팅에 빠지는 것을 막을 수 있음.\n",
    "    Dense(10), # 세번째 히든 레이어 (logit = score)\n",
    "    Activation('softmax') # softmax layer\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "callbacks = [EarlyStopping(monitor='val_accuracy', patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.8659 - accuracy: 0.7775 - val_loss: 0.3152 - val_accuracy: 0.9202\n",
      "Epoch 2/300\n",
      "54/54 [==============================] - 1s 11ms/step - loss: 0.3284 - accuracy: 0.9097 - val_loss: 0.2326 - val_accuracy: 0.9385\n",
      "Epoch 3/300\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.2622 - accuracy: 0.9281 - val_loss: 0.1961 - val_accuracy: 0.9478\n",
      "Epoch 4/300\n",
      "54/54 [==============================] - 0s 9ms/step - loss: 0.2234 - accuracy: 0.9390 - val_loss: 0.1711 - val_accuracy: 0.9552\n",
      "Epoch 5/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1965 - accuracy: 0.9456 - val_loss: 0.1534 - val_accuracy: 0.9603\n",
      "Epoch 6/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1746 - accuracy: 0.9514 - val_loss: 0.1438 - val_accuracy: 0.9617\n",
      "Epoch 7/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1574 - accuracy: 0.9559 - val_loss: 0.1316 - val_accuracy: 0.9635\n",
      "Epoch 8/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1433 - accuracy: 0.9600 - val_loss: 0.1245 - val_accuracy: 0.9665\n",
      "Epoch 9/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1313 - accuracy: 0.9636 - val_loss: 0.1169 - val_accuracy: 0.9695\n",
      "Epoch 10/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1196 - accuracy: 0.9664 - val_loss: 0.1113 - val_accuracy: 0.9705\n",
      "Epoch 11/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1103 - accuracy: 0.9695 - val_loss: 0.1066 - val_accuracy: 0.9690\n",
      "Epoch 12/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.1015 - accuracy: 0.9718 - val_loss: 0.1012 - val_accuracy: 0.9735\n",
      "Epoch 13/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0936 - accuracy: 0.9744 - val_loss: 0.0962 - val_accuracy: 0.9737\n",
      "Epoch 14/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0867 - accuracy: 0.9769 - val_loss: 0.0988 - val_accuracy: 0.9732\n",
      "Epoch 15/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0818 - accuracy: 0.9778 - val_loss: 0.0924 - val_accuracy: 0.9752\n",
      "Epoch 16/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0752 - accuracy: 0.9798 - val_loss: 0.0901 - val_accuracy: 0.9757\n",
      "Epoch 17/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0702 - accuracy: 0.9811 - val_loss: 0.0873 - val_accuracy: 0.9755\n",
      "Epoch 18/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0654 - accuracy: 0.9824 - val_loss: 0.0868 - val_accuracy: 0.9773\n",
      "Epoch 19/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0617 - accuracy: 0.9832 - val_loss: 0.0866 - val_accuracy: 0.9757\n",
      "Epoch 20/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0583 - accuracy: 0.9849 - val_loss: 0.0829 - val_accuracy: 0.9762\n",
      "Epoch 21/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0542 - accuracy: 0.9860 - val_loss: 0.0823 - val_accuracy: 0.9773\n",
      "Epoch 22/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 0.9872 - val_loss: 0.0825 - val_accuracy: 0.9757\n",
      "Epoch 23/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0478 - accuracy: 0.9881 - val_loss: 0.0800 - val_accuracy: 0.9780\n",
      "Epoch 24/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0452 - accuracy: 0.9886 - val_loss: 0.0794 - val_accuracy: 0.9772\n",
      "Epoch 25/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0423 - accuracy: 0.9897 - val_loss: 0.0790 - val_accuracy: 0.9780\n",
      "Epoch 26/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0400 - accuracy: 0.9901 - val_loss: 0.0794 - val_accuracy: 0.9782\n",
      "Epoch 27/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0380 - accuracy: 0.9907 - val_loss: 0.0794 - val_accuracy: 0.9775\n",
      "Epoch 28/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0358 - accuracy: 0.9914 - val_loss: 0.0789 - val_accuracy: 0.9767\n",
      "Epoch 29/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 0.9920 - val_loss: 0.0807 - val_accuracy: 0.9763\n",
      "Epoch 30/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 0.9931 - val_loss: 0.0763 - val_accuracy: 0.9777\n",
      "Epoch 31/300\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.0302 - accuracy: 0.9934 - val_loss: 0.0779 - val_accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=300, batch_size=1000, validation_split = 0.1, callbacks=callbacks)\n",
    "\n",
    "results = model.evaluate(x_test,  y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.07566794753074646\n",
      "accuracy : 0.9779999852180481\n"
     ]
    }
   ],
   "source": [
    "print('loss :',results[0])\n",
    "print('accuracy :',results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.reshape(x_train, (60000,28,28,1)) # gray scale이라 마지막 숫자 1(채널의 갯수 1)\n",
    "# 영상은 5차원으로 진행 → 1 뒤에 숫자가 하나 더 있어\n",
    "x_test = np.reshape(x_test, (10000,28,28,1))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "gray_scale = 255\n",
    "x_train /= gray_scale\n",
    "x_test /= gray_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy 계산\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes) # one-hot-encoding\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), # 이미지에서 conv2d를 많이 씀\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1),padding='same')) # padding을 해서 shape을 유지시킨다\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               200832    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 215,370\n",
      "Trainable params: 215,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=categorical_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_accuracy', patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "108/108 [==============================] - 15s 135ms/step - loss: 0.4924 - accuracy: 0.8640 - val_loss: 0.1113 - val_accuracy: 0.9692\n",
      "Epoch 2/5\n",
      "108/108 [==============================] - 13s 120ms/step - loss: 0.1055 - accuracy: 0.9685 - val_loss: 0.0742 - val_accuracy: 0.9810\n",
      "Epoch 3/5\n",
      "108/108 [==============================] - 13s 121ms/step - loss: 0.0690 - accuracy: 0.9798 - val_loss: 0.0574 - val_accuracy: 0.9847\n",
      "Epoch 4/5\n",
      "108/108 [==============================] - 13s 122ms/step - loss: 0.0541 - accuracy: 0.9833 - val_loss: 0.0478 - val_accuracy: 0.9877\n",
      "Epoch 5/5\n",
      "108/108 [==============================] - 13s 123ms/step - loss: 0.0450 - accuracy: 0.9858 - val_loss: 0.0500 - val_accuracy: 0.9857\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size=500, validation_split = 0.1, callbacks=callbacks)\n",
    "results = model.evaluate(x_test,  y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.040602538734674454\n",
      "accuracy : 0.9864000082015991\n"
     ]
    }
   ],
   "source": [
    "print('loss :',results[0])\n",
    "print('accuracy :',results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
