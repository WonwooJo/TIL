{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val=X_train[50000:]\n",
    "Y_val=Y_train[50000:]\n",
    "X_train=X_train[:50000]\n",
    "Y_train=Y_train[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 8, 4, 8], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val\n",
    "Y_val\n",
    "X_train\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rand_idxs = np.random.choice(50000,700)\n",
    "val_rand_idxs = np.random.choice(10000,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 9, 1, 7, 3, 2, 6, 0, 5, 8])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_rand_idxs\n",
    "np.random.choice(10,10) # defalut: 복원추출\n",
    "np.random.choice(10,10,replace=False) # 비복원추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.6509804 ,\n",
       "       0.75686276, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.99215686, 0.94509804, 0.8156863 ,\n",
       "       0.5411765 , 0.02745098, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.03529412,\n",
       "       0.99215686, 0.9882353 , 0.9882353 , 0.9882353 , 0.11372549,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.30980393, 0.99215686, 0.9882353 ,\n",
       "       0.9882353 , 0.9882353 , 0.11372549, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.1764706 , 0.99215686, 0.9882353 , 0.9882353 , 0.9882353 ,\n",
       "       0.11372549, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.58431375, 0.99215686,\n",
       "       0.9882353 , 0.9882353 , 0.92941177, 0.09803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.79607844, 0.99215686, 0.9882353 , 0.9882353 ,\n",
       "       0.5176471 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.38431373, 0.9882353 ,\n",
       "       0.99215686, 0.9882353 , 0.9882353 , 0.5176471 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.27058825, 0.93333334, 0.9882353 , 0.99215686, 0.9882353 ,\n",
       "       0.9764706 , 0.43137255, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.3529412 , 0.88235295,\n",
       "       0.7490196 , 0.99215686, 0.9882353 , 0.92941177, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.9411765 , 0.99215686, 0.99215686, 1.        ,\n",
       "       0.99215686, 0.93333334, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.1254902 , 0.94509804,\n",
       "       0.9882353 , 0.9882353 , 0.99215686, 0.9882353 , 0.7882353 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00784314, 0.5529412 , 0.9882353 , 0.9882353 , 0.9882353 ,\n",
       "       0.99215686, 0.972549  , 0.3254902 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.11764706, 0.9882353 ,\n",
       "       0.9882353 , 0.9882353 , 0.9882353 , 0.99215686, 0.47843137,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.9882353 , 0.9882353 , 0.9882353 ,\n",
       "       0.9882353 , 0.99215686, 0.17254902, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.11764706,\n",
       "       0.9882353 , 0.9882353 , 0.6392157 , 0.9882353 , 0.7019608 ,\n",
       "       0.05098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.11764706, 0.9882353 , 0.9882353 ,\n",
       "       0.9882353 , 0.9882353 , 0.27450982, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.11764706, 0.9882353 , 0.9882353 , 0.9882353 , 0.43529412,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.02745098, 0.5372549 ,\n",
       "       0.9137255 , 0.9137255 , 0.33333334, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.23921569, 0.58431375,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y data one-hot-encoding\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(units=2 ,input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10 ,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "70/70 [==============================] - 0s 4ms/step - loss: 2.2597 - acc: 0.1457 - val_loss: 2.2073 - val_acc: 0.1833\n",
      "Epoch 2/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2.1627 - acc: 0.1871 - val_loss: 2.1220 - val_acc: 0.2167\n",
      "Epoch 3/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2.0822 - acc: 0.2400 - val_loss: 2.0606 - val_acc: 0.2767\n",
      "Epoch 4/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 2.0191 - acc: 0.2800 - val_loss: 1.9928 - val_acc: 0.3033\n",
      "Epoch 5/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.9630 - acc: 0.2957 - val_loss: 1.9462 - val_acc: 0.2933\n",
      "Epoch 6/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.9132 - acc: 0.3157 - val_loss: 1.8887 - val_acc: 0.3067\n",
      "Epoch 7/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.8682 - acc: 0.3286 - val_loss: 1.8550 - val_acc: 0.3100\n",
      "Epoch 8/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.8297 - acc: 0.3329 - val_loss: 1.8170 - val_acc: 0.3233\n",
      "Epoch 9/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.7941 - acc: 0.3257 - val_loss: 1.7756 - val_acc: 0.3100\n",
      "Epoch 10/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.7635 - acc: 0.3343 - val_loss: 1.7592 - val_acc: 0.3267\n",
      "Epoch 11/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.7377 - acc: 0.3514 - val_loss: 1.7304 - val_acc: 0.3200\n",
      "Epoch 12/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.7115 - acc: 0.3429 - val_loss: 1.7358 - val_acc: 0.3300\n",
      "Epoch 13/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.6906 - acc: 0.3329 - val_loss: 1.6979 - val_acc: 0.3267\n",
      "Epoch 14/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.6708 - acc: 0.3614 - val_loss: 1.6806 - val_acc: 0.3333\n",
      "Epoch 15/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.6518 - acc: 0.3771 - val_loss: 1.6602 - val_acc: 0.3467\n",
      "Epoch 16/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.6340 - acc: 0.3643 - val_loss: 1.6454 - val_acc: 0.3967\n",
      "Epoch 17/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.6167 - acc: 0.3957 - val_loss: 1.6401 - val_acc: 0.3833\n",
      "Epoch 18/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.6017 - acc: 0.4014 - val_loss: 1.6337 - val_acc: 0.3833\n",
      "Epoch 19/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.5869 - acc: 0.4214 - val_loss: 1.6282 - val_acc: 0.3800\n",
      "Epoch 20/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.5740 - acc: 0.4114 - val_loss: 1.6090 - val_acc: 0.4000\n",
      "Epoch 21/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5602 - acc: 0.4214 - val_loss: 1.5940 - val_acc: 0.4100\n",
      "Epoch 22/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5477 - acc: 0.4186 - val_loss: 1.5847 - val_acc: 0.4167\n",
      "Epoch 23/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5365 - acc: 0.4257 - val_loss: 1.5839 - val_acc: 0.4100\n",
      "Epoch 24/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5254 - acc: 0.4343 - val_loss: 1.5772 - val_acc: 0.4100\n",
      "Epoch 25/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5139 - acc: 0.4329 - val_loss: 1.5639 - val_acc: 0.4000\n",
      "Epoch 26/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5048 - acc: 0.4300 - val_loss: 1.5570 - val_acc: 0.4167\n",
      "Epoch 27/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4937 - acc: 0.4400 - val_loss: 1.5530 - val_acc: 0.4067\n",
      "Epoch 28/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4842 - acc: 0.4343 - val_loss: 1.5430 - val_acc: 0.4200\n",
      "Epoch 29/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4755 - acc: 0.4443 - val_loss: 1.5625 - val_acc: 0.4033\n",
      "Epoch 30/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4670 - acc: 0.4500 - val_loss: 1.5394 - val_acc: 0.4200\n",
      "Epoch 31/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4588 - acc: 0.4500 - val_loss: 1.5357 - val_acc: 0.4233\n",
      "Epoch 32/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.4509 - acc: 0.4471 - val_loss: 1.5258 - val_acc: 0.4267\n",
      "Epoch 33/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.4433 - acc: 0.4657 - val_loss: 1.5425 - val_acc: 0.4100\n",
      "Epoch 34/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.4336 - acc: 0.4657 - val_loss: 1.5205 - val_acc: 0.4233\n",
      "Epoch 35/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.4265 - acc: 0.4643 - val_loss: 1.5235 - val_acc: 0.4100\n",
      "Epoch 36/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4194 - acc: 0.4729 - val_loss: 1.5232 - val_acc: 0.4133\n",
      "Epoch 37/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.4127 - acc: 0.4786 - val_loss: 1.5048 - val_acc: 0.4433\n",
      "Epoch 38/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.4049 - acc: 0.4814 - val_loss: 1.5083 - val_acc: 0.4233\n",
      "Epoch 39/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3981 - acc: 0.4757 - val_loss: 1.5055 - val_acc: 0.4367\n",
      "Epoch 40/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3926 - acc: 0.4857 - val_loss: 1.4940 - val_acc: 0.4300\n",
      "Epoch 41/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3842 - acc: 0.4671 - val_loss: 1.5084 - val_acc: 0.4100\n",
      "Epoch 42/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3798 - acc: 0.4871 - val_loss: 1.4873 - val_acc: 0.4167\n",
      "Epoch 43/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3730 - acc: 0.4814 - val_loss: 1.5038 - val_acc: 0.4133\n",
      "Epoch 44/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3681 - acc: 0.4986 - val_loss: 1.5013 - val_acc: 0.4200\n",
      "Epoch 45/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3606 - acc: 0.4971 - val_loss: 1.4968 - val_acc: 0.4033\n",
      "Epoch 46/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3563 - acc: 0.4857 - val_loss: 1.4977 - val_acc: 0.4267\n",
      "Epoch 47/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3515 - acc: 0.4971 - val_loss: 1.4793 - val_acc: 0.4200\n",
      "Epoch 48/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3452 - acc: 0.4986 - val_loss: 1.4854 - val_acc: 0.3967\n",
      "Epoch 49/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3399 - acc: 0.5000 - val_loss: 1.4861 - val_acc: 0.4033\n",
      "Epoch 50/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3343 - acc: 0.4986 - val_loss: 1.4643 - val_acc: 0.4367\n",
      "Epoch 51/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3282 - acc: 0.4986 - val_loss: 1.4892 - val_acc: 0.4033\n",
      "Epoch 52/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3270 - acc: 0.5000 - val_loss: 1.4683 - val_acc: 0.4367\n",
      "Epoch 53/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3198 - acc: 0.5000 - val_loss: 1.4771 - val_acc: 0.4167\n",
      "Epoch 54/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3150 - acc: 0.4986 - val_loss: 1.4884 - val_acc: 0.4533\n",
      "Epoch 55/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3113 - acc: 0.5014 - val_loss: 1.4885 - val_acc: 0.4000\n",
      "Epoch 56/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3075 - acc: 0.5014 - val_loss: 1.4786 - val_acc: 0.4300\n",
      "Epoch 57/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.3013 - acc: 0.5014 - val_loss: 1.4521 - val_acc: 0.4367\n",
      "Epoch 58/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2987 - acc: 0.5071 - val_loss: 1.4586 - val_acc: 0.4333\n",
      "Epoch 59/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2938 - acc: 0.5086 - val_loss: 1.4673 - val_acc: 0.4200\n",
      "Epoch 60/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2899 - acc: 0.5071 - val_loss: 1.4614 - val_acc: 0.4267\n",
      "Epoch 61/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2860 - acc: 0.5100 - val_loss: 1.4596 - val_acc: 0.4400\n",
      "Epoch 62/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2809 - acc: 0.5143 - val_loss: 1.4551 - val_acc: 0.4333\n",
      "Epoch 63/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2772 - acc: 0.5029 - val_loss: 1.4652 - val_acc: 0.4267\n",
      "Epoch 64/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2746 - acc: 0.5057 - val_loss: 1.4623 - val_acc: 0.4533\n",
      "Epoch 65/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2699 - acc: 0.5143 - val_loss: 1.4693 - val_acc: 0.4500\n",
      "Epoch 66/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2671 - acc: 0.5200 - val_loss: 1.4602 - val_acc: 0.4433\n",
      "Epoch 67/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2628 - acc: 0.5057 - val_loss: 1.4543 - val_acc: 0.4333\n",
      "Epoch 68/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2584 - acc: 0.5114 - val_loss: 1.4411 - val_acc: 0.4300\n",
      "Epoch 69/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2558 - acc: 0.5114 - val_loss: 1.4489 - val_acc: 0.4400\n",
      "Epoch 70/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2534 - acc: 0.5143 - val_loss: 1.4499 - val_acc: 0.4367\n",
      "Epoch 71/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2473 - acc: 0.5114 - val_loss: 1.4621 - val_acc: 0.4533\n",
      "Epoch 72/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2439 - acc: 0.5086 - val_loss: 1.4567 - val_acc: 0.4500\n",
      "Epoch 73/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2431 - acc: 0.5129 - val_loss: 1.4490 - val_acc: 0.4333\n",
      "Epoch 74/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2385 - acc: 0.5114 - val_loss: 1.4629 - val_acc: 0.4533\n",
      "Epoch 75/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2358 - acc: 0.5143 - val_loss: 1.4663 - val_acc: 0.4400\n",
      "Epoch 76/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2306 - acc: 0.5157 - val_loss: 1.4396 - val_acc: 0.4200\n",
      "Epoch 77/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2276 - acc: 0.5214 - val_loss: 1.4531 - val_acc: 0.4200\n",
      "Epoch 78/500\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 1.2248 - acc: 0.5129 - val_loss: 1.4664 - val_acc: 0.4600\n",
      "Epoch 79/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2223 - acc: 0.5257 - val_loss: 1.4407 - val_acc: 0.4267\n",
      "Epoch 80/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2200 - acc: 0.5214 - val_loss: 1.4389 - val_acc: 0.4267\n",
      "Epoch 81/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2164 - acc: 0.5214 - val_loss: 1.4707 - val_acc: 0.4533\n",
      "Epoch 82/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2130 - acc: 0.5314 - val_loss: 1.4465 - val_acc: 0.4467\n",
      "Epoch 83/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2104 - acc: 0.5286 - val_loss: 1.4589 - val_acc: 0.4467\n",
      "Epoch 84/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2106 - acc: 0.5214 - val_loss: 1.4535 - val_acc: 0.4500\n",
      "Epoch 85/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2065 - acc: 0.5229 - val_loss: 1.4577 - val_acc: 0.4433\n",
      "Epoch 86/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2033 - acc: 0.5243 - val_loss: 1.4608 - val_acc: 0.4600\n",
      "Epoch 87/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.2001 - acc: 0.5371 - val_loss: 1.4483 - val_acc: 0.4533\n",
      "Epoch 88/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1974 - acc: 0.5271 - val_loss: 1.4696 - val_acc: 0.4467\n",
      "Epoch 89/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1946 - acc: 0.5171 - val_loss: 1.4720 - val_acc: 0.4333\n",
      "Epoch 90/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1922 - acc: 0.5243 - val_loss: 1.4453 - val_acc: 0.4567\n",
      "Epoch 91/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1894 - acc: 0.5229 - val_loss: 1.4538 - val_acc: 0.4600\n",
      "Epoch 92/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1858 - acc: 0.5300 - val_loss: 1.4732 - val_acc: 0.4400\n",
      "Epoch 93/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1837 - acc: 0.5343 - val_loss: 1.4668 - val_acc: 0.4433\n",
      "Epoch 94/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1816 - acc: 0.5386 - val_loss: 1.4381 - val_acc: 0.4500\n",
      "Epoch 95/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1778 - acc: 0.5429 - val_loss: 1.4543 - val_acc: 0.4500\n",
      "Epoch 96/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1745 - acc: 0.5357 - val_loss: 1.4722 - val_acc: 0.4400\n",
      "Epoch 97/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1724 - acc: 0.5386 - val_loss: 1.4703 - val_acc: 0.4600\n",
      "Epoch 98/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1703 - acc: 0.5386 - val_loss: 1.4667 - val_acc: 0.4633\n",
      "Epoch 99/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1679 - acc: 0.5286 - val_loss: 1.4537 - val_acc: 0.4700\n",
      "Epoch 100/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1627 - acc: 0.5586 - val_loss: 1.4730 - val_acc: 0.4533\n",
      "Epoch 101/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1634 - acc: 0.5443 - val_loss: 1.4614 - val_acc: 0.4633\n",
      "Epoch 102/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1609 - acc: 0.5557 - val_loss: 1.4545 - val_acc: 0.4700\n",
      "Epoch 103/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1579 - acc: 0.5571 - val_loss: 1.4383 - val_acc: 0.4567\n",
      "Epoch 104/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1564 - acc: 0.5300 - val_loss: 1.4567 - val_acc: 0.4767\n",
      "Epoch 105/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1522 - acc: 0.5400 - val_loss: 1.4804 - val_acc: 0.4733\n",
      "Epoch 106/500\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1496 - acc: 0.5586 - val_loss: 1.4588 - val_acc: 0.4700\n",
      "Epoch 107/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1489 - acc: 0.5657 - val_loss: 1.4690 - val_acc: 0.4833\n",
      "Epoch 108/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1458 - acc: 0.5514 - val_loss: 1.4435 - val_acc: 0.4600\n",
      "Epoch 109/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1432 - acc: 0.5500 - val_loss: 1.4457 - val_acc: 0.4767\n",
      "Epoch 110/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1404 - acc: 0.5543 - val_loss: 1.4485 - val_acc: 0.4800\n",
      "Epoch 111/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1378 - acc: 0.5543 - val_loss: 1.4560 - val_acc: 0.4833\n",
      "Epoch 112/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1353 - acc: 0.5714 - val_loss: 1.4574 - val_acc: 0.4767\n",
      "Epoch 113/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1337 - acc: 0.5686 - val_loss: 1.4449 - val_acc: 0.4767\n",
      "Epoch 114/500\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.1310 - acc: 0.5643 - val_loss: 1.4730 - val_acc: 0.4633\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,Y_train,epochs = 500, batch_size = 10, validation_data=(X_val,Y_val), callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEGCAYAAADBr1rTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd1xW1RvAv4clQ3AgLhyg4gRFxZGWKydmppYzR1lqqWmZP22p7dLKlaZWWlbuVSmunJW5R+DEgYqiDNl7nN8fR/aLjHhF4Hw/n/uRe+855z6Xj7zP+zznGUJKiUaj0Wg0jxImRS2ARqPRaDRZ0cpJo9FoNI8cWjlpNBqN5pFDKyeNRqPRPHJo5aTRaDSaRw6zohYgv5iYmEgrK6uiFkOj0WiKFTExMVJKWWwMkmKnnKysrIiOji5qMTQajaZYIYSILWoZ8kOx0aIajUajKT1o5aTRaDSaRw6tnDQajUbzyFHs9pwMkZiYiL+/P3FxcUUtSrHF0tKSGjVqYG5uXtSiaDQaTclQTv7+/tja2uLk5IQQoqjFKXZIKQkJCcHf3x9nZ+eiFkej0WhKhlsvLi4Oe3t7rZgKiBACe3t7bXlqNJpHhhKhnACtmP4j+ven0WgeJUqMcsqN5ORY4uL8kTKpqEXRaDSaHImIgMWL4e7dopakaCk1yiklJZ7ExDskJxe+6yosLIzFixcXaK6npydhYWF5Hj9r1iy++OKLAj1Lo9E8+syfD+PHg7MzvPEGBAQUtURFQ6lRTiYmlgCkpDxc5ZScnPzAuV5eXpQvX77QZdJoNMWTdeugeXMYOBAWLIDGjWHTpqKW6uFTipRTGUAYRTlNnz6dK1eu4O7uztSpU9m/fz+dO3dm6NChuLm5AfDMM8/QsmVLmjRpwrJly9LmOjk5ERwcjJ+fH40aNeLll1+mSZMmdO/endjYB1cbOX36NG3btqVp06b069eP0NBQABYsWEDjxo1p2rQpgwcPBuDAgQO4u7vj7u5O8+bNiYyMLPTfg0ajSSc5GV55Bb7+Ou9zzp0DHx948UX44Qd17uICAwYoa6o0xSyViFDyjPj6TiYq6rTBeykp0YAJJib5Kxxbtqw7Li7zcrz/2Wef4ePjw+nT6rn79+/n6NGj+Pj4pIVmL1++nIoVKxIbG0urVq0YMGAA9vb2WWT3ZfXq1Xz77bcMHDiQjRs38vzzz+f43BEjRrBw4UI6duzIjBkzeP/995k3bx6fffYZ165do0yZMmkuwy+++IJFixbRvn17oqKisLS0zNfvQKPR5I933oElS8DODl54AWxscp+zdi0IoZQRQP368Ndf8Pbb8OWXkJIC33xjXLkfFUqN5aQwQcqUh/Kk1q1bZ8oZWrBgAc2aNaNt27bcvHkTX1/fbHOcnZ1xd3cHoGXLlvj5+eW4fnh4OGFhYXTs2BGAkSNHcvDgQQCaNm3KsGHD+PnnnzEzU98/2rdvzxtvvMGCBQsICwtLu67RaAqf1avh88+hY0cV4LBmTe5zpFQuvY4doVq19OsWFvDFF7BtG7z3nvFkftQocZ9QD7Jw4uNvkZAQQNmyLRDCuHrZJsPXpP379/PHH3/wzz//YG1tTadOnQzmFJUpUybtZ1NT01zdejmxbds2Dh48yG+//caHH37I2bNnmT59Or1798bLy4u2bdvyxx9/0LBhwwKtr9GUZI4dg+Bg6NWrYPPPnIHRo+GJJ2DXLmjRQllQo0c/eJ63N1y4AJMmGb7v6VkweYorpcpySg+KiC/UdW1tbR+4hxMeHk6FChWwtrbmwoULHD58+D8/s1y5clSoUIE///wTgJ9++omOHTuSkpLCzZs36dy5M7NnzyYsLIyoqCiuXLmCm5sb06ZNw8PDgwsXLvxnGTSaksj//qeCEbL+Sf/zD3zwATz5JIwalfP82bPBygo2bFBWz7hxcPy4Oh7EunVgYpLu0ivtlDjL6UGkK6dYTE0Lr2Ghvb097du3x9XVlV69etG7d+9M93v27MmSJUto2rQpDRo0oG3btoXy3B9//JFx48YRExNDnTp1WLFiBcnJyTz//POEh4cjpeT111+nfPnyvPfee+zbtw9TU1MaN25Mr4J+LdRoSjApKXDyJERFwS+/KMUCyk03dKjaD6pUCfbuhXnzIGugbUKCcr/17w+VK6trw4fDtGmwdCl4eGQev3kz/P13+jO6dAEHB+O+Y7FBSmmUA6gJ7APOA2eBSQbGDAP+vX8cAprltq61tbXMyrlz57Jdy0Z8vEwJDpIRYcdkXNyt3MeXQvL0e9RoSjCXL0updn+kbNZMypQUKRMTpaxbV53fuyflrl3q/u7d2een3vv118zXR4+W0tpayqAgdR4VJeULL6ixlpZS2thIaWcn5caNxns3IFoa6fPeGIcx3XpJwBQpZSOgLTBeCNE4y5hrQEcpZVPgQ2AZxiIqCnHND9NEc6OEk2s0muLPqVPq35deUntHR47ATz/BlSvKpVehArRqpcYcOZJ9/pYtYG0N3bplvv7KKxAbqwId2rZV+1A//KACHCIjlaUWHq4sLo3CaG49KWUAEHD/50ghxHnAETiXYcyhDFMOAzWMJQ/W1gCYJpiRZKWVk0ajyc7Jk2BmBp9+qiLsFi5Ue00tW0KfPmpM+fLQoEF25ZSSAr/+Cj16qD2njLRsqdx3W7fCgQPqGbt3q/0rjWEeyp6TEMIJaA4Y+K6Rxmhgew7zxwBjACwsLAomRJkyYGKCabwgISUOKaUudqrRaDJx6hQ0aaL2lYYNU/tEoBJpM35ctGkDO3YoB2Dq9RMn4NYteOYZw2s/9pg6NHnD6NF6QoiywEZgspQyIocxnVHKaZqh+1LKZVJKDymlR4Hzc4QAKytM4lOAFKRMKNg6Go2m2HD5slIgeUFKZTk1b67Ox45V/7Zpkz2svE0bCAyEGzfSr23ZAqamkCUeSlNAjKqchBDmKMX0i5TSYHUoIURT4Dugr5QyxJjyYGWFiEsEaZwaexqN5tEgJkbtG7m4wOuv521OQIBSOC1aqPPmzVVtu2+/zWw1gVJOkNm1t2ULdOgAWQq/aAqI0ZSTUD6z74HzUsqvchhTC9gEDJdSXjKWLGlYWSGSkhHJWjlpNCUVHx8VtLB8uVIi8+er4INUbt2C/fvV8c8/aq8IlNUE6ZYTwMSJcL88Zibc3NROQapy8vZWdfByculp8o8x95zaA8MBbyFEarG7t4FaAFLKJcAMwB5YfH//J0lK6WFgrcIhNSgi3oSUIg6KKFu2LFFRUXm+rtGUZP74A0JD4bnnCr6GlPDdd/Daa1CuHOzcCZ07Q8+eykVXtqy69sMPkJShrdubb8KcOWq/SQho1iz3Z1lYKAvryBH13KlT1TOHDCm4/JrMGDNa7y/ggREHUsqXgJeMJUM27ofQmCaYkZRSsNJAGo2mcElIgBEjVMkgd3flissvERFKAa1Zo8K4V66EqlXVvbVroXVrpfgsLNS4/v1VNYZly1Qy7ejRynJycQFb27w9s00bFTDx669K6X31lU6gLUxKVfkizMzA3ByTBEFyclxqIvB/Ztq0aZn6Oc2aNYsvv/ySqKgonnzySVq0aIGbmxu//vprnteUUjJ16lRcXV1xc3Nj7dq1AAQEBNChQwfc3d1xdXXlzz//JDk5mVGjRqWNnTt3bqG8l0bzMFi9Wu33SKma6+WX48eVK279evjkExVFl6qYQO0Bbd8OH34IV6+qyLsuXaBTJ6WYrK3Vc0+dyuzSy43WrVXu0osvQsOGMGFC/mXX5EzJK180eTKcNtwyA4DYWExTkrGylGBqQ570s7u7+l+cA4MHD2by5Mm8+uqrAKxbt44dO3ZgaWnJ5s2bsbOzIzg4mLZt2/L000/nKYR906ZNnD59mjNnzhAcHEyrVq3o0KEDq1atokePHrzzzjskJycTExPD6dOnuXXrFj4+PgD56qyr0RQmfn4qWq1LF1Wyp0YumYtSqlYQbm7w/PNqzo4dyhWXG1KqgIWpU5UyOnAA2rc3PLZ+fXj33ezXK1eGmTNhyhR1fv9POE+kBkWEhsKqVWBunve5mtwpXZYTKFs+RVlMhdU+o3nz5gQGBnL79m3OnDlDhQoVqFWrFlJK3n77bZo2bUrXrl25desWd+/ezdOaf/31F0OGDMHU1JQqVarQsWNHjh07RqtWrVixYgWzZs3C29sbW1tb6tSpw9WrV5k4cSI7duzAzs6uUN5Lo8kvU6ao8O0lS6BuXRUp96Bm0Lt3q2CCKVNUNe569dScxMTcnzVnjvou2quX+j6ak2LKjQkTVFIt5M9ycnaGmjVVcm5elKkmf5Q8y+kBFg4AISGIa9eIdwIz2+qUKVO9UB777LPPsmHDBu7cuZPWffaXX34hKCiIEydOYG5ujpOTk8FWGYbIyeXYoUMHDh48yLZt2xg+fDhTp05lxIgRnDlzhp07d7Jo0SLWrVvH8uXLC+W9NJqsnD0LjRqp73kZ2btXtRP/6COVwPrRR+rP0dxcVeo2xJdfqpI+Q4ao/aC5c9WH/ddfPzgEfPt2mD5dVQ9fsyZ7qHd+sLBQe0dvvZVuDeUFIeDoURUIoTECRV3cL79HgQu/phITI+WxYzL21mkZHe2b93m54OPjIx977DHp4uIib9++LaWUct68eXLChAlSSin37t0rAXnt2jUppZQ2NjYG10m9vnHjRtm9e3eZlJQkAwMDZa1atWRAQID08/OTiYmJUkop586dKydNmiSDgoJkeHi4lFLKU6dOyWbNmhXoHXThV01ubNyoipV27y7lnTvp1xMTpXR1ldLJScrY2PTrr76qxv/yS/q15GQpT5+WcvZsde/TT9PvpaRI2aOHlOXKSRkYmH59924pp06VcssWKY8cUffd3VUBVU3eoJgVfi15llNulCkDQmCaYEpSSkyhLdukSRMiIyNxdHSk2v02lsOGDaNPnz54eHjg7u6er+Z+/fr1459//qFZs2YIIZg9ezZVq1blxx9/ZM6cOZibm1O2bFlWrlzJrVu3eOGFF0i5n7Dx6aefFtp7aUovYWGqGGnt2upcSmUBOTjAwYNqK/bzz1Wpnz//VPlFGzeCpWX6GvPmqeujRyt334kTamxoqLrfrFl6JQZQ1sjcudC0qdojWroU/v1X5Q9FRytXHqhnbtmSt9bnmuKJkIUUsfawsLGxkdHR0ZmunT9/nkaNGuV9kXPnSDFNIbp6HDY27piYlD4dbYh8/x41D4Xbt1XI8xtvwMPaTvTzUzlC9+6pPaFatVTh0scfVy63Dh1g0CA4fz59TrduKqQ6q4stKEglxV6/rvaUOnZUR4cO6YovK6+/rpJnd+2Cl1+G+Hj1/Js34dAh9ayWLY32+iUSIUSMlLLYqPPSqZz8/JBhoUTVScbKuj5mZjqAALRyehTx91eRb76+ymqZOtX4z7x6VSmmiAgVmNCunVI6/fsri+nGDWWxxMcrqyb1I6R585wj1u7dg7g4qJ7HLd6wMJVzdO+eWvPgQRW6rSk4xU05lb5oPYCyZRFJyZgkQHJy4bn2NJrC5MYNZWHcuaPyaJYuTS+1U9gkJ6s8n/nz1TMjI2HPHvjiCxVRN3WqSjZ95ZV0V1qZMsoiat1aHQ8Kpa5YMe+KCVRbis8/V++7dKlWTKWREqOc8mUB3k8BN4s1JaUQ952KM8XNgi7u7N6tcm9++snw/chI1esnJESNfe891fBuz56c1zx5Evr1U66zL75QDeyyEhOj9nxSU+GiotTYGjVUOZ7Jk1VS6t696nzsWOVC+/JLpXweZqLpiy8ql+DIkQ/vmZpHhxLh1rt27Rq2trbY29vnvUfTv/+SZCmJdzTFxsbVCJIWH6SUhISEEBkZibOzc1GLU6JJSlJJn6kxK1WrKqWTtTnd2LGqTtz+/fDEE8qFVqOG2qfZuDE9eTW1c+udO0qhlC+v+hH9/bcKGpgyBcaPV9/Hzp5VodfnzqXXkPP3V2WDunZVSqBDB7W/lJGbN1Xww+DBsGiR0X9FGiNR3Nx6JUI5JSYm4u/vn+ccIgCCg5GxMcQ7SMqUqYkQJcaILBCWlpbUqFEDc53mXijcu6ci0+rWVcmaUqrosg8+UO2/R4+GAQPA01NFtE2alD53506V1Dl1aub8oP/9T9Vvu35d5RAtWaICCszN1TF0qKqiXa6cqrb9wQeq2kLFiqqu3MqVSkl99plyGR48qM6nTcu9CV5EhCqcmjW3SVN8KG7Kqchj2fN7GMpzKhArVkgJ8uhyZFjYP4WzpqZUk5Ii5VdfSdm0qZRCqBwekLJGDSkbNFA/u7hIuW5d+pwuXaSsUkXK6Gh1HhoqpaOjlI0bZ84XklJKX1+1hrOz+nfaNPXMB3H0qJR9+qjxTz4pZUBA4b6zpvhAMctzKr3fgzp1AqD8aYiKOlW0smiKPVKqigVvvKGskQ8+UGHQixapaLfKleGXX1Todca2EO+/D3fvwuLFsG2b2me6cwd+/DFzvhCovaSuXeHaNXjnHeUazM2L3aoV/Pab6mG0a1fmgqgaTVaEED2FEBeFEJeFENMN3O8khAgXQpy+f8wwmiyyBLj1Cop0ciLEKYDgJUNp2HBFoaypKdkY+nOR9/v5fPWVimb7+uv8ub969FBBD1IqN93s2WpvyBDXril34YAB/61kj6b0kZtbTwhhClwCugH+wDFgiJTyXIYxnYA3pZRPGVncUlghIgOiUyfK/7aay/cOFLUomodASAgcO6aKdTZunP3DPTxc7dWEh6tzCwvw8FDj4+Lg+++V4rhxw/D6EyeqUOz8Ko3Zs1WU3PDh6njQtp+zszo0GiPQGrgspbwKIIRYA/QFzj1wlpEo1cqJTp0w+/FHTC9eI66FP5aWudT31zwyHD0K336rCnV27KhcXlmVQmCg2vQ/cEAd3t7p9ypVUrkzqa4zPz9V2dpQHpGzs1JOAQGqQsILL2R/lpOTaphXEGumWTPYty//8zSafGImhDie4XyZlHJZhnNH4GaGc3/AUCncx4QQZ4DbKCvqbOGLqpUTAOVPQbjnn1ha6h7LxYUPPlB7NN99p87HjlXRa6n88ouyQqRUSaPt2qlQ6LZtVbTbgQNKGaW2c3BwULlEHTqoKtmgcoAOHVJjExPVflKnTtqdpim2JEkpPR5w39D/7KyO7JNAbSlllBDCE9gCFKB3ce6U6j0nAFmrFsH1Arj3zWgaNFiS+wRNkRMaClWqwGuvwUsvqdDolStVKR1XV2XluLioMV9/rWqw6Qh5TWknD3tOjwGzpJQ97p+/BSClzLGStBDCD/CQUgYXsrilOFrvPqJ9e8qdMyM8/GBRi6LJI1u2KEtm0CBV1ufLL1UOzvvvq/vffaeSSz//XFlKWjFpNHniGOAihHAWQlgAg4HfMg4QQlQV9ysdCCFao3RIiDGEKfXKiXbtsLgbR7LfeRISAotaGk0eWLdO7QN53HdQ2NurgIING9Re1KefKvdcly5FK6dGU5yQUiYBE4CdwHlgnZTyrBBinBBi3P1hzwI+9/ecFgCDpZHcb6XerceJE+Dhwdn3oPLEDTg4DCi8tTWFwrlzSgFVqaIi7qpWVWV5PvssfUxoqFJYpqaqOsP+/SpQQqPRKIpbhQhtOTVtirS2pvxZM8LCtGuvKPH3V717UkO5ARISVDBDixZw6RJs3qzq0w0alHluhQoqYOHePWUxacWk0RRvtHIyN0e0bk2F81aEhel8p6Jk8mS1X7R+ffq1v/5SyiooSCmcRYtUsIO7u+H5/fqpPSiN5lFg3dl17LuWe55AYHQgs/bP4lxQkaQUPZJo5QTQrh1Wl6KJDT5DYmJoUUtT4gkOVmHbM2em5xXt26eqbYMKeEjFy0slw/79twoLP31aVU8wFM5tZwebNhlWXBrNwyYoOogRm0cwfU+2KkBpJCQn8MWhL3BZ6ML7B96n+0/d8Y/wf4hSPrpo5QTQrh0iOQW7i2jryYhERqoK2E5Oqqr2Bx8oN15CgqrK7eQE48bBH3+osaCUU8eOqkbc/v3KnTd2bBG+hEaTR5adWEZ8cjwnbp8gIj4i0z0pJb9d/I0mi5swdfdUnqj1BJsHbSYiPoLeq3pnG18aMZpyEkLUFELsE0KcF0KcFUJMMjBGCCEW3C8y+K8QooWx5Hkg9/sFlDtrTmjo7iIRoaQTHg7du8OcOdC3r+otNGMGLF+u8pC8vVXTuyFDVO+inTtVHbnz51VbCVBh42vWqHJCGs2jwI7LO/jrxl/ZrickJ7Do2CKq2FQhWSbz942/0+7dibpD95+703dNX8xMzNg+bDtbh27lmYbPsHHgRs4FncPzF09m7pvJzH0z8fL1epiv9OhgrHLnQDWgxf2fbVEFBRtnGeMJbEdlJrcFjuS2bqG1zMhKo0YyvENlefhwPeOsX4oJDZWydWspzcyk3LQp873331ftHDp3Vu0fEhOlrFRJymHDpFy0SN27eLFo5NZoHkRUfJQs82EZySxk/7X95ZV7V9Lu/fLvL5JZyPVn10vzD8zl/3b9L+3eRK+J0uJDC7ng8AKZkJSQbd0Vp1ZIq4+sJLOQzEJaf2wt78Xc+8/yoltmpCm9ACnlyfs/R6Li5h2zDOsLrLz/uzsMlBdCVDOWTA+kXTts/o0iNvoysbFXi0SEkkhsrLKYTp1Se0r9+mW+P2MGbN+uLCIhwMwM+vSBrVvV3lO9eqqduUbzqLH32l7ik+MZ6jaUHZd30HhRY97e8zaR8ZHMOzyP+vb16d+oP60dW3PgutouSEpJYu3ZtfSp34eJbSZibpo9Q3yU+yhi3olBzpScGnuKmMQYvj/1/cN+vSLnoew5CSGcgObAkSy3DBUazKrAEEKMEUIcF0IcT0pKMo6Q7dphGhaD9U24d2+XcZ5RCnnvPVUJfN06ePppw2N69lT9jlLp21e5AXfvTnfpaTTGJCohiv1++3O8H5cUx64ru1I9PgB4+XpR1qIsy59ezqUJlxjYZCCf/vUpzvOdOXb7GK+1fg0TYUInp04cv32cyPhI9l3bR2B0IEPdhuZJLveq7nSs3ZGvj35NUoqRPvseUYyunIQQZYGNwGQpZdZdvrwUGkRKuUxK6SGl9DAzM1Kt2vvlBKocK09oqFZOhcFff6keR+PGwTPP5H1et25gZaV+1spJY2wSkhPou6YvnX/szKGbh7LdT5EpPL/peXr83IM1PmsAtR2yzXcbXet0pYxZGRztHFnZbyWHRx+mXsV6VLetzkj3kQB0rN1R7Tvd/JvVPquxK2OHp0ve/2NPajOJ6+HX+fXCr4XzwsUEoyonIYQ5SjH9IqXcZGCIP5Bxe7sGqgz7w8fJCVq2pPKf5oSG7iGllH1LKShSKpfcokXq+OEHuHhRVfQeNUr9WufMyd+a1tbKmrKx0cm0GuMipeTl319m77W9mJmYsdp7dbYx/9v9Pzae34iNuQ3zj8wH4GzQWW5G3KS3S+9MY9vUaMM/o//h+uTrlLUoC0C7mu0wMzFj15VdbDq/iX4N+2FpZpntOTnxdIOncSrvlPbs0oLRWmbcLw74PXBeSvlVDsN+Aybcb2rVBgiXUgYYS6Zcee45rKZPx+wWREYepVy5dkUmSnHh0CEVYZcVa2u137RvnyrKml8WLFAVI7K2KtdoCgspJTP3z2TlmZXM6jiLs0FnWXduHXN7zsXMRH00Ljq6iC//+ZIJrSbQoFIDJm6fyGH/wxy8rqrJ9KrXK9u6QgjMRPpHq42FDa0dW/PN8W+IS4pjiGv+WvOYmpgysfVEpuyawsmAk7SoVjRBzQ8bY1pO7YHhQJcM/eY9sxQR9AKuApeBb4FXjShP7gxQdfUcDgq975RHtmxRVb+vXVPN/c6dg6VL0ys1FNTyqVFDVRTXaIzB6Tun6fxjZz48+CGj3Ecxo+MMhrgOITA6kL3X9gJwPug8k3dO5qn6TzGv5zxGNhuJXRk75h+Zj5evF82qNMPRLtsWuUE61u5IXFIcDtYOPFnnyXzL+2LzF7Ext+G7k9/le26xpajDBfN7GC2UPBV3dxnZtKw8caKtcZ9TAkhJkbJuXSl79ixqSTTGZvru6XKH745CXfN80Hk5YvMIGRgVmOc5l4IvyVFbRsmtF7cW+Lmf//W5FLOEtP/cXn5z7BuZlJwkpZQyNjFW2n1qJ0dtGSVTUlJk95+6y3Kflssk3xs73pBmH5hJ0/dN5Vt/vJXnZ+68vFMyC/nq1lcLLPfhm4dlbGJsgedTzELJi1yA/B5GV04ffywlyENrhYyPz/sfTWnEx0f9D1qypKgl0RiT2MRYKWYJ+ey6Zwt13Re3vCiZhWz7XVsZkxDzwLERcRHyzZ1vSvMPzCWzkI8vf7xAz0xMTpQVPqsgu67sajB3aNSWUdLuUzu5zmedZBZy7j9zM92/eu+qNHnfRDIL+ef1P/P83NjEWDn619HSN8S3QHIXBsVNOenyRVl59lkAKh2UhIRsK2JhHm1Sa+DlFCKuKRlcDb2KROIT6FNoa8YnxbPx/EaaODThiP8Rhm8eTopMyXH8m7ve5Mt/vmR40+GMazmOQzcPERqb/zqYR/yPEBoXypgWY6hgVSHb/SGuQ4iIj2DElhE0rNSQ8a3GZ7rvXMGZfg374WDtQNsaefc7W5pZ8t3T31GvYr18y1xa0copK/XrI5s2pcqfFoSElK7QzfyyZYvaF6pWNGnTD41DNw+x8MjCh/Ks3Vd2M2v/rAJ98GZl5ZmVfHHoC2ITYw3e33R+EytOrch1Hd8Q37R/45LiDI5ZdHQRG89tzLNsOy7vIDw+nDnd5vBF9y/YeH4jU3dNzXn8lR30b9Sf7/t+z0j3kaTIFHZdyf++sJevF6bClG51uxm838W5C5VtKhOXFMe8HvMMJsku77ucoy8fTQua0BgHrZwMIPr1w9Y7gQi/nSQnG/7DLk0EB4OfnzpSey3dvAnHj+cvf6m4suDIAqbunqr84Ebmoz8/4v0D7+Oy0IXFxxYXOPEyNjGW8V7jmbp7Ko0WNWL92fWZ5JdSMnX3VF71epXgmOAHrnUp5BIAyTKZC8EXst1PSkli2h/TGLRhEDsv7zS4RnxSPAnJCWnnq31WU8m6El3rdOX1tq8zodUEvjr8FV8f/TrbXL8wP26E36CTUycAWlVvhb2VPdt8Db+nCoMAACAASURBVHs24pLi8Avzwy/Mj7tRdzPd2+a7jfa12lPesrzBuWYmZrzX4T0mt5lMj3o9DI6xK2OHU3kng/c0hYdWTobo1g0hwe5ELKGhfxS1NEXKokWqeoOzszoqV4bx42HJEnW/NCinC8EXiE+OJyQ2xKjPSUpJ4vjt4zzd4Gncqrgx3ms8gzYMIjklOd9rbb20laiEKD7q/BHlLMsxcMNAVp5ZmXb/UsglroZeJS4pjmUnlj1wLd97voj7+fLed72z3T8beJboxGgszSx5dv2znLlzJu1eckoy3574llrzatH2u7ZExkcSlRDFbxd/47nGz2Fuao4Qgnk95/F0g6eZtGMSv1/8PdP6qZUbUpWTqYkpPev1ZPvl7dlcgQGRATRe1Bjn+c44z3em2pfV+OH0DwDcirjFmbtnsuUmZWVC6wnM7Tn3gWM0xkcrJ0O0bo20tcX+pDnBwaXXtTd/PkyYAL17w4oV6hg5Er79Fj75BBo0UEdJJjklmYshFwGM3mfHJ9CHmMQYBjcZzN4Re5nddTabzm9i6u6c3V05sdpnNdXKVmP649M5OeYkDSs1ZPnp5Wn3UytdN63SlEXHFpGYnJjjWr73fPGo7oGFqYXBfacjt1RVsm1Dt1GuTDk8V3ky0WsiE70m4vGtB2O2jqGmXU3+vfsvAzcMZOO5jcQmxWbK9zE1MWVV/1W0qNaCwRsHc/rO6bR7+/32U8m6Eo0dGqdd83TxJDgmmOO3j6ddi0qI4qnVTxEYHcgiz0Ws6LuC1o6tmbp7KmFxYWy/vD1trubRRysnQ5ibIzp1wv6UBSEhvyNl/r+5FnfmzVOdZQcMUA38Ro1Sx7JlcPkyvPkmfPppUUtpfG6E30jbZzG2cjrsfxiAtjXaIoRgavupvNb6NeYenpuvPa/wuHC8fL0Y2GQgpiammJqYMsR1CH9e/zPtHbb5bqOJQxM+6fIJtyNvs+HchhzX8w3xpZFDIxpWaoh3YHbL6bD/YSpZV6JD7Q54DVP15lb5rGKVzyrikuJYM2ANx14+xpKnlrDj8g5e2fYKNexq0L5W+0zr2FjYsHXIVspalOWdve+kXT9w/QAdanfARKR/XPWo2wOBSFOySSlJDN6glNq659bxaqtXGeU+im96f0NITAjv73+fbb7bqGlXkyYOTfL8u9QUHVo55US3bljcjMb0eiAREVnr1ZZsvL1hyhTo3x9Wr1ZJthmpVUuVJMpaYTw39vvtp9qX1bgTdafwhDUy54PPp/38MJRTZZvKmfYzvurxFc80fIZJOyYZ7BtkiM0XNhOfHJ/JMhniOgSJZK3PWiLjIzl4/SCeLp70cumFS0WXHEvjxCTGcCvyFi4VXXCr7GbQcjrsf5g2jm0QQtC0SlMuTrhIyP9CCPlfCOfHn2eQ6yCEELzU4iXefvxtYpNiGdxkcCZlk0qVslUY32o8Xr5eXAy+mLZ31Kl2p0zj7K3taVujLdt8t+ET6EOPn3uwzXcbizwXZbKMmldrzsstXubrY1+z8/JOPF08EYbaKGseObRyyomuXQGoeNKU4OAtuQwuvsTEwE8/Qdz9ICwpVVfa8uWV+y6rYvov7Li8gztRd9h6aWvhLWpkUgMABKJQlNOZO2fSLKSsHLl1JO1DPhVTE1N+7vczjnaOvLb9NYP7T0kpSfxw+oc0+Vb7rKZOhTq0dmydNsbF3gWP6h6s9lnNnmt7SExJxNPFExNhwmttXuPIrSMG5bp87zIA9e3r41rZlZsRNwmLC0u7HxYXxvng83kOq/6oy0dseG4DMzrOyHHM2JZjsTC1YOHRhRzwU60mUvebMtLbpTfHbx+n2ZJmnAo4xdKnljLOY1y2cR91+Qgbcxtik2Jz3W/SPDpo5ZQTDRuCoyOVvR0IClr/UCK1ioJ334URI1RgQ2wsbN6s6uF9+CFUrFi4zzoZcBKgWHX2PB90HgdrBxztHP+zckpKSaLP6j50WNEh7UM3ldDYUC4EXzD4IW9jYcOcbnM4decUK05nD/1efGwxL/z6Ag2+bsBbf7zFnqt7GNxkcDYLYYjrEE4EnGD+kfnYWtjSvqZyq41yH4W1uXWmgIlUUsPIUy0nIJP1dOzWMYA8KychBAMaD8C2jG2OY6qUrcJQt6H8cPoHfr34KxWtKtKkcnZX3HNNnqOyTWVe9XgV34m+jGk5xuB6DjYOzO42m1rlatHFuUue5NQUPVo55YQQ0K0bdsciiYv2IzLyWFFLVOicPw8LF6o26bt2qWTaKVPAzQ3GGP47LzBSSk7dOQXA7qu708KKE5MT6bqyK18e+rJwH5gLJwNO0mJpi0z5RFJKev7ck5/O/JR27XzweRpWakgNuxo5Kqe5/8zF7Ru3bOHaWdlyYQs3I25iW8aWZ9Y+w/mgdJfh0VtHgZw/5Ac1GcTjtR7n7T1vEx4XnnY9OCaYmftn0qF2BzxdPPns789IlskMccteXHRQk0EIBPv99tO9bve0HJ6yFmXpWqcr2y9vzyZ/ahh5vYr1cKuSXTkd9j+MQNCqeqsc37sgTGoziejEaDZf2EzH2h0NugDr29fn7pt3Wei5EHtr+weuN6blGK5Pvo6NhU2hyqkxHlo5PYiuXTEJjcb2ihmBgWuKWpoC8eef0L49TJwIGzZA6P3PYinh9ddVWwovL9XqYs8elcs0f77qSFuY+Ef4ExwTTI+6PYhKiErbP9lwbgN7ru3hzd1vZlIKxsbL14tTd06lKQWAO1F32HllJ0tPLE27diH4Ao0qNaKGXQ1uRd7Kts5q79W8sesNbobfZOCGgXT8oWMmpZOR+Ufm41zemaMvHaWMaRk8V3mm5eEcuXUEgcCjuofBuUII5vecT3BMMO/tey9NiczYN4PI+Ei+6f0N659bz4FRB1j61FJcK7tmW8PRzpEOtTsAZHNvedbzxC/ML1sek+89X6qWrYptGVtq2tXEroxdpnDyw7cO08ihEeUsyxmUu6CkNtkDwy49TclHK6cHcX/fyfGcC4GB65APKK/yKBIRAc8/ryyk5cvhuedUte+pU5Uy2rkTZs5UuUsjRiiX3pdfQufOhS9LqtX0Zrs3sTC1YNsllUA5/8h8XCq60NmpM6N/G51WEdrYpH77zxh9lnrtH/9/uBd7j6DoIEJiQ5TlZFuDm+E3M1kWB68fZNSvo3ii1hPcnnKbpU8t5VzQOQZtGJTNAjlx+wR/3fiLia0nUrdiXbYO3UpgdCB9VvchOiGaw/6HaVK5CXZl7HKUuUW1FoxtOZaFRxfSZWUXVnmvYumJpYxvNT4tzLpD7Q45urcAXm7xMjbmNvRyydzqITWIIGtiq+89X1wqugBKQbpWdsUnSP2epJQc8T9CW0fjlI+f1n4aFqYW9KhrOBlWU7LRyulBVKkCHh5U8oogIe4W4eF/F7VE+eKNN1RPJC8vZTH9/beKwPvqK3jxRbWtNmFC+vi+fdUcY3Ay4CQCwWM1HqOTUye8Lntx2P8wR24d4bU2r7Fp0CZc7F3ov7Y/tyON328yVSlldFGlXkstjZNqRTRyUJZTdGI0EfGqmXNwTDDPrHkG5/LObBm8BWtza8a0HMOcbnPwDvRmn9++TM+bf2Q+ZS3K8mLzFwHwqO7BmgFrOBFwgiEbh6QFQ+TGQs+FLPZcjPddb4ZtGkYFywrM6jQrz+89rOkwgqYGUbVs1UzXa5ariVtlt2z7gb4h6coJwNXBFe+73kgpuRJ6hZDYENrUyF3ugtDLpRdh08JoUKmEJ9NpDKKVU25MmoSZ7y0qHbMgMHBtUUuTZ7y84PvvlZXUti1YWEC7dioy78IFlcO0cmXBo/GuhV4jJCbvFRNO3TlFw0oNsbGwwbOeJxeCLzBl1xTsytgxstlIyluWZ+2zawmPD2fLhYJHR/57998HJpSCKqWTupeS1XKqbFMZeyt7vHy90sLIU/ecID2c/OD1g4TGhfLd099R0So9cmSI2xAcrB0yhWYHRAawxmcNL7q/mMn91adBHxb0XMDvl37nXuy9PAUVmJmY8UqrV/Cd6MuMDjP4qd9PBguYPggrcyuD1z1dPPnzxp9pCjgiPoK70XdxsU9XTm5V3AiNC2WNzxqWn1JJvfkpgJpfcpJVU/LRyik3Bg2CmjVx3lCOoKD1xaJ9e2AgvPwyNGkC77+f/b6LC8ydC60KsIcdFB3EuK3jqLewHsM3D8/zvJMBJ2lerTmQ7kI6dPMQLzV/KS1yq4lDE+pWqFvgaL5LIZdotqQZI7eMfGCF64shF0lKScLR1pFzQefSwrO9A71pWqVpWmmcc0HnsDKzola5WmlN5VKV06mAU5gKU1pWa5lpbUszS8Z5jOP3i79z5d4VklOSeWXbKyTLZCa2mZhNlvGtxzPlsSkIBE/UeiLP71rBqgLvd34/m3vuv9DbpTdJKUn8cVWV7MoYRp5KauDD0E1D+fSvT1UknU5q1RgBrZxyw9wcJk/G5ngQlt6BhIXty31OEZKQoLp+3LsHP/8MZcoU0rrJCXz1z1e4LHThu5Pf0cShCbuu7MpUWPP47eO8/NvL2SyXoOgg/CP8aVFVtZd2sXehXsV6mAgTJrRO9ysKIfB08WTvtb05VtJ+EKn7Vat9VvPe3vdyHJe6oT/YdTBxSXFcCb1CikzhbOBZXB1c00rjrD27lgaVGmAiTLJZTifvnKSRQyOD3+xf8XgFMxMzFh5dyBs73+DXi78yv+f8HNslzOk2B7/JfkXuvnqs5mOUK1Mu7ctBxjDyVNrUaMPZV89y5KUjHHnpCP+O+xdTE9MikVdTstHKKS+8/DKyXDlqrbMgIKDo2iRPnKj2izKydSs88QSsWgXJySqB9s8/VQCEu3v+1o9LiuNe7L1s1718vXD7xo0pu6bQtkZbvF/xZtWAVSTLZNafW5827q09b/Hdqe/YfGFzpvmpwRAtqrVIuzaz40w+7PwhzhWcM431dPEkNik2rdhnTkgpMyWDgqpA4WjryJgWY/jkr0/49sS3Buf6BPpgbmLOgEYDAKWsroZeJTYpFrcqbvSo2wMTYcKdqDs0qtQIgOq21YHMllPG98lINdtqDGwykK+Pfs2CowtU1e0MSjgrQghqlav1wPd9GJiZmNGjXg8VyRhwKi2ism7FupnGNXZoTGvH1rR2bJ3nNuUaTX7Ryikv2Noixo6l0oFEov7dREJC4EMXISQEFi+G6dPhktouIToaxo2Dw4dh2DCoXVtVC58+HYZkT3PJlTG/j6H50uaZ2jT8feNveq/qjUCwbeg2djy/g0YOjXCt7IprZVdW+6wGVGXqVHdQ1lI4pwKUcnKvmq4tn2/6PG8/8XY2GTo5dcLKzOqBrr2klCT6rulL3QV1iYyPBJSy2u+3n05OnVjUexE96vbgVa9XCYoOyjbfO9CbBpUa0KxqMwQCn0CftMAI18quaaVxQO03AViYWlDFpgq3Im8REBlAQFRAmiVoiMltJ5Msk+nfqD9fdP8ix3GPGn3q91HvtqwFXx/7GufyzlibWxe1WJpSiFZOeeW110CYUO3XJO7c+fGhP37XLkhJUceUKerap5/CrVuqosP69WDm8SNtRq/mo48evJaUko8PfpxWsQGURbDKexU3wm9kslpWnlmJjbkNx8ccz1bNeYjrEA7dPMT1sOvMPzIfSzNL3uvwHoduHkqrHADKBeZc3jlPG/eWZpY8WedJvC57pbVrnv33bJafWk5ySjJSSiZtn5QWRPDrRVU1/lLIJe5G36WTUyfMTMyY2XEmSSlJHLx+MNszfAJ9cKvshrW5NXUr1sU70DvN1Ze6f+JZT71rquUEpCXiplqCqXtohvCo7sG5V8+xZsAagwmkjypDXIewY9gOtgzawpZBW9jx/I6iFklTSik+fzVFjaMjom9fqu804871pQ8952nbNqhUCT76SLnyliyBL75QFtPjj0OMy0quNx/FkZpD2Xwx5wrToCyHd/e9y/DNw9P2hxYfW4xEYm1uzWpvZQ0lJCew4fwG+jbsS1mLstnWGew6GIBFxxbx078/MbzpcN5s9ya2FraZrKdTAace+EGeFc96nlwNvcrFkIt8dPAjpv0xjdG/jcbjWw8m7ZjE4uOLefOxN6lVrlaa5ZaqUFMTNz2qe2Btbp3NPRgRH8H18OtppXhSi5n6BPlQp0KdtAoCw5oOo7NT57SkVcignAxYgoZo5NDIYCfVRxlTE1N61OtB34Z96duwb6ZgCI3mYaKVU34YNw6zsCTK7rxCWNj+h/bY5GTYsQN69VJVHerVg1deAVNT+OwzFQjw0m8v0cW5C+1qtuP5Tc9z6OahHNdLVT7ngs7xzfFviEmMYemJpfRt0JdnGz/LxvMbiU+KZ/eV3dyLvZepunVG6lSoQ9sabZlzaA5xSXG81uY17MrY8WLzF1l3dh0Xgy8y/Y/pqh9QNcOVDwyRaqG9su0VZuyfwYhmI1g9YDUhMSEsPLqQ5xo/x+fdPmdwk8HsurKL4Jhg9l/fT3Xb6mlBB+am5rSv2Z4D1zPXsDsbeBYgrYKCa2VXfO/5cuzWsTSFBeBU3om9I/dSpWyVtGuOtqq+3sk7J6lXsd4DE2Y1Gs1/o5CL1JRwnnwSWbcOjltv4D9kKRUqPJwikseOqT0nT08VfTd3LvTpA2+/DVGWF+j/c3/q29dn48CNJKUk8dj3j/H06qcZ0WwEAkHNcjWZ0HoCZiZmSClZc3YNPev1JDklmZn7ZxKdEM292HtMajOJ2KRYVp5ZyY7LO1h/bj0VLCvQvW73HGUb4jqEw/6H6Vqna9oH/sTWE1lwZAFNFjchWSYzstlIxrcen+f3rV2+Nk0cmrDfbz9dnLvwbZ9vsTC14OkGT7Pz8k56ufTCRJgwxG0Isw/NZsO5DRzwO0Anp06Zip12curEO3vfITgmmErWlYD0vKbUOnFuld1IkSlcC7vGULehD5Srhl0NQuNCOXTzUCaLSqPRFD5aOeUHExPEmLGUmzaNS8c3EV/vDmXKVM193n/EywtMTKD7fR3x1FPg6wt16kg6rxyLmYkZ24Zuo7xleQC2D9vOU6ue4tuT3yKlTGuhPc5jHIf9D+MX5sf7nd7Ho7oHTb9pytt738a9qjsdancgKSWJStaVWH56OXuu7mGo21AsTC1ylG2w62CWHF/Cu0+8m3atbsW6jG05lgshF5jddTatHPOfUDWh9QQ2nNvAhoEb0p5vbW5Nv0bpTaSaVWlGw0oNmf33bAKiArLVYEs9P3j9IP0b9QfUflNZi7Jp0XEZa9BltJwMkRpOfifqDs2r5t1NqdFo8o926+WXF15AmptT7bckAgKW5j6+EPDygscey9zCol492HB+PQevH+TjLh9Tu3zt9HsV63FhwgUi34ok8q1IOjl14t297xIaG8pqn9VYmlnyTMNnaOzQmPGtlEUzqc0khBCYm5rzXOPn+O3ib0QnRufo0kulsk1lzo0/R0enjpmuf/PUN+wbua9AiglgnMc4/hjxR5rCNYQQgiGuQ7gWdg3IXiDUo7oHVmZWmdpTeAd641rZNS1IwcXeJU35GSqWmpFU5QTkGEau0WgKB62c8ouDA+LZZ6m624yAq4tJSYk36uMCAuDECeidpUdaTGIMU3dPxb2qOy+1eCnH+anVrEPjQnl377usPbuW3i690/ZLPn7yY5Y+tZRhbsPS5qQqpGplqz3y7qtUWauWrZopWRRU+Hf7Wu3Zf30/oKIUfQJ9cHVIV0JmJmY0qtQIcxPzXDf/MyonbTlpSiJCiJ5CiItCiMtCiOkPGNdKCJEshHjWWLIYTTkJIZYLIQKFENn7Oqv75YQQvwshzgghzgohXjCWLIXO6NGYRSZRbn8ggYHrcx//H9h6v2msZ+Yobub8PYcb4TeY33N+rhn6Tas0ZWzLsSw+vpjA6MBM1lBZi7KMaTkmU1RZ+1rt0+Y86tn/LvYudKvTjWcbPWuw/Xan2p3wvuvNvdh7fP735wTHBNO+VvtMY3rU7UHXOl1zjaxLTTitYVcDBxuHwnsJjeYRQAhhCiwCegGNgSFCiMY5jPsc2GlUeYzV4VUI0QGIAlZKKbP5S4QQbwPlpJTThBAOwEWgqpQy4UHr2tjYyOjoaKPInGdSUpBOToTXuMeVhY1o0eKowQ/G/8rBg0op1akDZ86o/ocAgdGBOM1zok+DPqx9Nm/FaENiQnBZ6EJSShJ337xbagpq/nXjL55Y8QTPN32en//9mSGuQ/i5/88Fzj2yn21P+5rt+W3Ib4UsqUZjXIQQMVLKHLstCiEeA2ZJKXvcP38LQEr5aZZxk4FEoBWwVUr54NyVAmK0gAgp5UEhhNODhgC2Qn2qlwXuAY9+VVVQgRHDh1Pus0+Jv3aciHpHKFfuv1dmPnPnDDXsamBvbc/+/cqVV6uW6ruUUfdtu7SN2KRY3nr8rTyvbW9tn1b1u7QoJlCFSq3MrPj535/pULsDK/qu+E9JsYs9F2cr56PRFBPMhBDHM5wvk1Iuy3DuCNzMcO4PZOqHIoRwBPoBXVDKyWgUZbTe18BvwG3AFhgkc8hsFUKMAcYAWFjkHDn2UBkxAvHJJ1Tda4l/o68oV27df1pOSkmXlV3oULsDc9tsxtMTnJ1h717VViojXpe9cLR1pFmVZvl6Rre63f6TjMWRMmZl6FqnK5fvXWbzoM2UMftvlXAHuQ4qJMk0modOkpTyQQmHhtw/WV1r84BpUspkY3iLMlKUyqkHcBqlgesCu4UQf0opI7IOvK/dl4Fy6z1UKXOiQQNo25Yae65w6Ln1RDudxcam4K0DwuLCVDmeC7/yWMRVYmPrsHZtdsWUmJzIriu7GNRkkFFciSWR9c+tRyKxNLMsalE0mkcZf6BmhvMaKOMhIx7AmvufPZUATyFEkpTSYBM2IYSrlNJg3EFuFGW03gvAJqm4DFwDGhahPPln5EgsLgVhd8UaPz8DjZPywY3wGwBIJGuufo2VFTRqlH3c3zf/JiI+IludO03OlDEroxWTRpM7xwAXIYSzEMICGIzybqUhpXSWUjpJKZ2ADcCrOSmm+ywRQhwVQrwqhMg5L8QARamcbgBPAgghqgANgKtFKE/+GTgQLCyot7s+QUHriYryzn1ODqQqp/r29fnX7HuaNI/E1ECgnJevF+Ym5jzp/GSBn6XRaDRZkVImARNQUXjngXVSyrNCiHFCiHEFXPNxYBjKIjsuhFglhMjT/oIxQ8lXA/8ADYQQ/kKI0Vle8kOgnRDCG9iD8mMGG0seo1CxIowdi92609TcVOY/WU83I9Q+5OddZ5NsFoFFa8OVz7f5bqND7Q5p3WM1Go2msJBSekkp60sp60opP75/bYmUcomBsaPyEqknpfQF3gWmAR2BBUKIC0KI/g+aZ8xovQeWFpBS3gZyLtpWXPjqK7h1i7oLN3HBaiNR752hbNn8BSqAspzMTcxpbt0HbrbF12k+PoGdEAgcbByobFMZvzA/zgWd46XmOSfdajQazaOCEKIpagunN7Ab6COlPCmEqI4yXjblNFfX1vuvmJnBqlWk9OlFgy/2ccV5BHXHns53sMKN8BvUsKuB978mcHgyQTUH4/aNqvVmbmLOpDaTsLe2B9D7TRqNprjwNfAt8LaUMjb1opTythDi3ZynGTEJ11g8Ekm4hoiOJsnVmTgRRMzfq6hcLX+taJ9Y8QSmwpRut/bz7ruS9ae3I83Ue26/vJ0fTv+ARFKnQh0uT7ysI/U0Gk2+yC0J91FDK6dCRK5dgxg8BN/3KuA84wZmZtkb9GXl3j0ID4dOv9amY+2OxK1eycmTcPly5nEnbp/gvX3v4eniyYTWE4z0BhqNpqRSFMpJCOECfIoqh5QWMiulrJPbXF34tRARzw0kuVkDai4L5fqlmXmaM3o0eLRO5lbELWra1eT0aWhmYMuqZfWWeA3z0opJo9EUJ1YA36Cq/3QGVgI/5WWiVk6FiYkJpnMWYnkX5OJ5xHn9CGPGwJdfGhweFKQKu95LCCBZJlPFqhaXLxtWThqNRlMMsZJS7kF56a5LKWehCi/kig6IKGy6dSOl8xPUW/QnLBqlrpmbw/DhULlypqGrV0NSElRtcIM7QEJQLaTUykmj0ZQY4oQQJoCvEGICcAuonMscII+WkxBikhDCTii+F0KcFEIU/zBwI2GyeBlRA1txdiaE7pkHiYmwYkW2cT/+CC1awOCxKgF303LVndXd/aGKq9FoNMZiMmANvAa0BJ4HRuZlYl7dei/er3nXHXBAxa1/ln85SwkNG2K9+i+iPRty0XohslMHWLoUUtLr2vr4wMmTMGIEVG2gEnD/2VmT8uVVJXKNRqMpztzv+zRQShklpfSXUr4gpRwgpTycl/l5VU6pccuewAop5RkMV7DV3MfExIJ69eYTF3eF4AHV4do12L077f7KlSpFasgQ8I+4gZUoB/F2NG2auT2GRqPRFEeklMlAS1HAvJe8KqcTQohdKOW0UwhhCxhsb6FJp2LF7lSq1I/zDTeRUqkCLFEVQJKT4eefoVcvtQ11I+IGdexrUaUKtG+fy6IajUZTfDgF/CqEGC6E6J965GViXgMiRgPuwFUpZYwQoiLKtafJhfr1l3I8wp07vWKptup3hL8/By7VICBAufQAbobfpHaFmvx1AWyKTYqcRqPR5EpFIITMEXqSB5QtSiWvyukx4LSUMloI8TzQApifXylLIxYWDjRq9AsXe3am2s/AW29xqP5KQND9fkjJjfAbtHFsQ/l8FZTXaDSaRxspZYGNmLwqp2+AZkKIZsD/gO9RyVQdC/rg0kSFCp2o8tgM/EZ+gPMPP3O8/ts0aNAIOzuITogmJDaEWuV0FIRGoylZCCFWkL2bLlLKF3Obm9c9pySp6hz1BeZLKeejWqtr8oiT0wzCX+tIQG9Tjl+yxaOcL5DeKkMrJ41GUwLZCmy7f+wB7ICovEzMq+UUKYR4CxgOPHE/RNC8AIKWCuLi4NgxeOKJ9GtCmNK4yVp2jO7BR/Q4tQAAIABJREFUrW01aHnsddjbh5u1kwGoWa5mDqtpNBpN8URKuTHj+f0+f3/kZW5eLadBQDwq3+kO4AjMyY+QpYl586BDB9iQpQ2XhUUVYhNWAdC02lnk0KHcuKm652rLSaPRlAJcgDx92OVJOd1XSL8A5YQQTwFxUsqVBZevZLNmjfr3lVfg7t3M986fb4yJSQpm7x5Cht/jxo8LEQgcbR0fvqAajUZjRIQQkUKIiNQD+B3VETdX8lq+aCBwFHgOGAgcEUI8W1CBSzIXL8KZMzB2LERGwrhxkLEryfHj0KiRoHKn/lx6LRGfGD8cZVnMTbWXVKPRlCyklLZSSrsMR/2srr6cyKtb7x2glZRypJRyBNAaeK+gApdk1q5VFR5mzIAPP4QtW1TCLSgldfw4eHgI6tdfyrU+zfitITx7OBI+/rhoBddoNJpCRgjRTwhRLsN5eSHEM3mZm1flZCKlDMxwHpKPuaWKtWtVIET16vDGG/DYY/D66xAaCrduKTefhweYmlpxILYjySYwtIw1vPsuvPNOZjNLo9FoijczpZThqSdSyjAgT83u8qpgdgghdgohRgkhRqHCAr3yLWYJ5+xZOHcOBg5U56amsHixUkyzZimrCZRyik2M5btTv9CrTgdiJycT/Exl+OQT6NIFli9XkzQajaZ4Y0jH5ClKPK8BEVOBZUBToBmwTEqZp02t0sTatWBiAgMGpF9zd4eXX4ZFi1SxV1NT1a9plfcqQmJDmPrE+zRs8jM+rwVy541myJs3VXvcqlXh+efh0CFtTWk0muLKcSHEV0KIukKIOkKIucCJvEwUsph98NnY2Mjo6OiiFiMbUkLDhuDoCHv3Zr4XFAT160NYmFJMp05Jmi1phhCC02NPI4Tgxo3ZXL06jVo1p1EnpL/SZD/9BBER4OamCvENGaIeoNFoNPlECBEjpXyo1TuFEDao+ISu9y/tAj6WUub6If5AyylrGGCGI/J+WGCpZN06FSYeF5d+bc0auHQJhg3LPt7BQbn1QLn01p9bj3egN5PbTCa1mnzNmlOpVm0sN25+zi3HY/D112qTaulSsLaGqVOhZk2Ypg1WjUZTPJBSRkspp0spPe4fb+dFMaVOLlaHtbW1LCqio6V86SUplZ0k5YgRUqakSHn7tpQVKkjZpo2UiYmZ51wMvigP3TgkExKkfPFFKZduPSKtPrKSrb9tLeMS4zKNTU5OlP/++7Tct0/IwMBNmRe6dEnKkSPVg7/7zrgvqtFoShxAtHzIn9fAbqB8hvMKwM68zNVuvTwSFqai8M6ehenT1d7RRx/BV1/Bnj3qOH0aGjRInxOTGEOjRY24EX6Dvg36MqH1BIZuHIptGdv/t3fm8VEX5x9/TzabTXZzXxASICAgR7jl8ireWBQUPFCpVau09UKrlWr9VWy1rVVbtGotKooW8VbEIhVpACsKBOQIh4QgRyA3uTZ3dp/fH7O5IIEASTabzPv12ley35nvfJ/ZZL+f7zPzzDN887NviHXEHnMdl6uMLVsuwunczNChnxERcVHDQr0J1OrV+jV+fDv03GAwdAa8NKz3nYiMPNGxpmizcHCl1AKlVI5SKvU4dSYqpTYrpbYrpVa3lS2twcsv663VP/1UB9U9/jhcfbUOF//3v2HuH0t56LupLP1+ad05z6x9hgNFB/jF6F+w8oeVXPLWJbjExbIblzUpTAAWi52kpKUEBfVn27YryM9f3rBQjx8mJMC0aZCR0dbdNhgMhtPBrZSqS1eklEqkiSzlTdFmnpNS6nx09tk3RSSpifJwYC0wSUQOKKVipfFaqibxhudUVQWJiTBkiN5pvay6jPQj6fRxDGXiRIiKgpufXszMj28k0D+Q5J8m0yOkBwNfGMgVA67gvWvfI7Mkk3nfzmP64OmMjR97wmtWV+ezZcsllJZuZ8iQ94mOnlJfuG2b3jI3NlZHX/QyefkMBsPx8ZLnNAkd6V3rfJwPzBKR/5zw3LYc1vOo5GfNiNOdQA8RefRk2vSGOC1cCLfcAsuXw2WXwezPZ/PihhdJuyeNXqF9UAquencKGzM3EuQfRFFlESO7j+SrA1+x665d9A7vfUrXra4uYOvWSTidmxg06G1iY6+tL1y3Di69FCIjITlZq6fBYDA0gzfEyXPdWGAWsBkIBHJEZM2JzvNmlocBQIRSapVSaqNS6ubmKiqlZimlUpRSKTU1Ne1oog59ePZZSErSWlBUUcSCzQtwiYsX1r+AxQKFlUdYvmc5NyTdwLKbluEWNyv2ruChsx86ZWECsFojGD58BaGh49mxYwZZWW/VF44bpye6Cgvh3HP1eKOPzR8aDIbOjVLqdvQ+Tg94Xm8Bc1tyrjfFyR8YDUwGLgP+Tyk1oKmKIjJfPKGI/v4t3YKqdVixQo+iPfCAzpm34LsFOKucjIobxWvfvYazysmHOz6k2l3NDUk3MCBqAMtuXMasUbOYc+7ph337+4cybNhywsMnsmvXTzl06MX6wrPO0l5TeDhMnQpXXglffKE3k9q9G9zu076+wWAwnAazgTHAfhG5ABgJ5LbkRG+KUwawXHQcfB6wBp19okPxt79BXJxe/+pyu3h+/fOc1+s8XvzxixRVFrFw80IWpy6mf2R/RsWNAmBcwjj+eeU/sVvtrWKDxeJg6NDPiIq6grS0u0lLm43b7fEgR4yA777T7t3q1XrccexYHTY4aJBeL1VS0ip2GAwGw0lSISIVAEopm4jsAs48wTmAd8VpCXpXXX+llB0YB+z0oj3HUFCgHZFbbwWbDZbuXsq+wn3MHjeb8QnjGRs/lqe+fopV+1ZxQ9INdQtq2wKLJYikpI9JSLiPQ4eeJzV1CjU1nnXQVqsOG/zhB1izBj77DObPh4gIuOcePR+1cmWb2WYwGAzNkOEJfvsEWKGUWgIcbsmJbRmttxiYCEQD2ehMtFYAEXnZU+fXwK2AG3hVROadqN32DIh4912YMUOnt5swAS5YeAF7C/aSfm86/n7+LN62mBs/uhGAnXftZGD0wHax6/Dhf7J7910EBw9j6NBl2Gzdm6/87bc6ud+uXVqwbr21XWw0GAwdC28FRDS4/o+AMPSIWdUJ65tFuM3z059qJ2Tr3iz+b9UjvL75df5y8V/49Tm/BqDaVU2f5/oQ64hl0883tYtNteTnf8727dcQENCNYcP+g93ev/nKRUVwzTXw5Zdw9916FfGJcvRt2KBD1Lt1a13DDQaDV/C2OJ0sRpyawe3WicH7XPMKO3r+isqaSmaPm82TFz1JgCWgrt7O3J0EWAI4I/KMNrfpaIqL17Nt22QAhgz5kPDw85uvXF0N992nVxNbLNolnDlTR/rZj5obS06GSy7RIYrr10NAQNNtGgwGn8HXxMlsGNgMGzdCbnkmG7vdxei40Wy/cztPX/p0I2ECGBQzyCvCBBAaOpaRI9fi7x/Fli0XcejQP5qvbLXqfTvS0nTW2o8+0sETERFw8cXaUwI4eBCuv15nq92yRafDMBgMXQKl1CSl1PdKqT1Kqd80UT5VKbXVk9knRSl1blvZYsTJw47cHUT/JZq1B9cCOiURY/6Bmxpem/Ia/aOOM2zmRez2/owevY6IiEtJS7uTXbtux+Uqa/6Evn3huef0lrzLl8O99+odEsePh4ce0sN/FRXae7rpJr19/ObN7dchg8HgFZRSFuBF4HJgMHCDUmrwUdVWAsNFZARwG/BqW9ljxMnDF+lfkF+ez93L7sbldvHZ8gr8x7/MlWde6TXPqKX4+4cxdOin9Or1CFlZr7Fx41k4nVuPf5LDoT2np5+GnTv1BodPP62H8RYu1JtTPf88REfrybe0tKYX+e7apYcGk5PbpnMGg6G9GAvsEZG9noCFd4CpDSuIiFPq54IctDBP3qlgxMnDtxnf4u/nz3dZ3zFv9QI2Vi6mxpbL7HGzvW1ai1DKQt++TzJs2ApqagrYuHEsGRkv0KI5xbAwHcm3ejW8/77OaAs6NdL8+XoV8oABOojijju01wVw4ICem/r6a+1l5ee3XQcNBsPp4l+bacfzmnVUeTxwsMH7DM+xRiilrlZK7QL+jfae2gQTEOEhcV4iY+PHkunMZEvGLkqyYjnjDD/S7t/apuuX2oKqqlx27bqFI0eWERV1JWeeuYCAgOhTb3DPHr1OavVqPVdlt+vhvueeg6ws7WHdfjtMmaLFzcc+L4OhK3CigAil1LXAZSJyu+f9T4CxInJPM/XPB34nIhc3VX66tG8uoA5KljOL/UX7uXfcvUxMnMjof54FsXnM+dGrPidMAAEBMQwd+hmHDj1PevpDpKQMY9Cgt4mImHhqDfbrp18//7kexrvjDrjzTggM1KuUzztPi9ScOTojRd++OmtFfr4OxAgK0uckJLRqPw0GQ6uSAfRs8D6B4yyYFZE1SqkzlFLRniw/rYrxnIAlu5Zw1btX8fVtX9PPdjbdf3YXjlFLyHk0jSBrUKteq70pKdnMjh3XU16+h8TEufTu/Qh63vM0cLth0SKdeeK88/QxlwsuvFBnqKglJESHsFdW6jmsb77RQ4gGg6HdaYHn5A/sBi4CDgEbgBtFZHuDOv2AdBERpdQoYCmQIG0gJGbOCT3fZPWzMrL7SBYvBvn330mettvnhQkgJGQEo0dvpFu3G9m373ds3nwhTue202vUzw9+8pN6YQK9duq99/Q6qjVr9MLf4mIoL9dDgmlpOkS9nbPKGwyGliEiNcDdwH/QqeTeE5HtSqlfKKV+4ak2HUhVSm1GR/Zd3xbCBMZzAuDChRdSUlXChjs2MHq0njJJSWnVS3gdESErayHp6Q9QU1NEfPydJCb+Hqs1vH0MeOUVmDVLZ9CNitI5oUpLYdgwnbx25sz6TRPdbvj1r2H7dvjkEz18WIvTqYcJLafp/RkMXQyzCNfHcLldrD+0nvHx40lNhU2b4OZmd5byXZRSxMXdwrhxu+nR4+ccOvQiKSkjKCpa2z4G3HGHzlCxeDG8/rre5mPQIL3a+be/heHDYckSPQx4883w17/Cf/6jRaqWt97Si4aDg7Wg3XKL3ra+oECXi+jzDQaDz9PlPaet2VsZ/vJw/nX1v9jyr5v429/g8GGdIKEzU1y8jh07bqSiYj+JiY/Rq9fD+Pm1cXyMiB7e69sXGu7LlZ6uh/w2boTBg/Wi4D/9CXJy9J4lS5boc6dPh7PPhjFj9Nqs9et10IXFoueyij1Z2p97TgdsGAyGOnzNc+ry4vTKxleY9dksdv4yjQtH9GPMGH0v7ArU1BSze/cvycl5G4djOAMGvExY2HjvGFNZqb2kl17Soel33qmPTZigtwIpL9fe1Zdf6kAL0EEY69fDsmXaewoL01nYV63SKT4mTTr2Om63njNryLp1cOgQTJvWtG179mgvzuXSInnBBXo40mDwIXxNnBARn3rZ7XZpTW775DaJeipK1qxxC4i8/36rNt/hcbvdkpPzoXz9dbwkJyvZtesOqazM8p5B5eWN33//vYjDITJkiEhe3onPLykRGT5cJDRUZNMmkUWLRC64QCQ6WsRmE/H3F3nuufr6+fm6TCmRL79s3JbbLfL66yJ2u4iWJf2yWEQeekikrOy0u2voRLjd3rbguACl0gHu4S19dfk5p3WH1jE+YTw7d+r1TGPGeNmgdkYpRUzMNMaO3UlCwv1kZb3OunX92b//z7hcFe1vUMPgB9CZKXbs0GHoUVEnPj84GD79VAdNjBqlM1fs369zBs6eDeecAw8+qCcXQW8fUlCgw+JnzqzPfpGfryMSb70Vxo3Tw5H5+ZCRoee6/vIX7T3t29eKnTf4LOvW6YCeZcu8bUnnwdvqeLKv1vScXG6X+P/eXx7+8mF58EH9YO1ytVrzPklp6S7ZunWKJCcja9f2lqyst8XdwZ8ImyQlRWTWLJEVKxr/UfPyROLiRAYNElm5UntCDzwgsnWrSGCgyGWXac8qIkJ7SH/4g0hNzbHtr1wpEhwsMnVq+/WpI7N/v0hhYeu0lZ+vvdgXXhB54oljvela9u0TmT5d5KWXRIqLj9/m7t0iDz8s8te/inz4ocjOnc17Oq++KvKb3zR/3aOpqBAZPFj/L8XEiGRmNi5vje+P2y0yebLIG2+cchP4mOfkdQNO9tWa4pTtzBbmIn9f93eZOlX/fxk0R46slA0bRkhyMpKSMlYKClZ526TW4z//0f/6VqtIQoIeChQRefllqRu6u/hikW3bjt/On/+s637xxbFl69eL/OQnIk89dezN6micTpHPPhPZvl2kulrfdO+/Xw9Nnn22Ftq2IidHZOlSkd//Xt/Am8Ll0p/Nli1Nl5eU6KHR4cNFqqpOz57du0XCwqTRMOoTTxxbr6xMZORIET8/XSckROTRR5sWgsxMkV69GrcJ2uarrmr8+X7+uR7iBd2f5j6Thvzud7r+s8/qB5xJk7Qda9boh6Cf/vSUP4463n1XX2PBglNuwoiTD4nT5szNwlzk/e3vy+DB5iH4aNxul2RmvuGZj0K2bJkkxcWbvG1W6zB7tv73//DD+mNut8i8eSKfftqyp92KCpEzztBPNbU35QMHRGbO1G0HB0vdHNWll4rce6++ga1Yoc8VEfnvf0X69q2/YQYG6voWi8i0aSKxsfpm+bOf6af9luJ0itx9t8h114l88MGxXkBJif6Hb3iznjDh2H6XlWnvBET69au3uyHPPFPfxp//3PjzacpDcTpF/vc/7aH+4Q8iRUX6eGWlyFlnaa91+XKRjAz9Gdjt+vda3G79GSulRf3bb7XIgH7waEhpqW7TbhfZuFF7zhs3irz2msgtt4h06yYSFKQ/o/R0fe2hQ/Xkc2Sk/hs+80y9jUezZYuex5w5U79/8UVtxwUXaPscjqbtOhkqK/X/yNChTXvxLcSIkw+J0+dpnwtzkTX7/ic2m8iDD7Za052Kmpoy2b//afnqqwhJTka2bZsuJSUn8Co6OjU1J/aMWsKSJfprNHu2yPXX6xuVzaaHkIqLRXbtEpkzRyQpqV6sQN+0zj23/qb/0Ucib74p8qtfiTzyiB4mE9FDZQ88oNsF7Um9887xbdqzR9/IlNLeAWgv7Ne/FsnO1t7SmDHa63j0Uf2EX3tTXbSovp3sbJFx43Q7t9yiy598svG1yspEuncXuegiLRCBgSJpadr7GzlSn5OYqD+PJ54QOe+8+r7UvgYP1jbPmXPsA0N6ukhAgPZCRbQw1Yrh44/X16uo0NcZObJ+GLemRuTqq7X9n37a9GeVna1FGUR69NDitGePLtu/X/er4efXUOTLykRGjdJDebm59fZNnqzPuftuLYb9+on079+0sNeek5ysP78hQ0SiovTrgw90+bx5ur3PP2/2T94SjDj5kDi9/t3rWpy2pQuIzJ/fak13SqqqCmTv3t/JmjUhkpysJDX1Ot8XqdPF7Ra55BL9VQoP10Kyb1/zdfPz9TDaL3+pb0QPPKCf7k9EVpbI00+LDBxYL4a1T9FZWXr4cPZskZtv1nZEROin9epq7andeKMWI7tdpGdPLSJLltS373LpG21CgvZsvv9epE8f7VV89JGuM326ft+wfy+8oO1JTtbeTWioyOjRWhRDQ0X+9Cc9j1c7/DZypBahTz8VOXRIzy1FRuqhPKX0POHRPPywPve110QuvFD/PnXqsRPEb72lyxYv1mU/+5l+3zA6synKy0VuuEF7q00JwPr1IjNmaPsmT9aejNtdf6zh51jb3q5d9e+XL5djhierqvTD0Ztv1j+kdOumxfSXv9QPD6CjQqOitEie5tyVEScfEqc/rvmjMBdZury07vtlODFVVfmSnv6wrFkTLMnJSGrqNVJWtsfbZnmPzEx9Q3Q62/5aNTUi992nv7pTpmh3PyhI6p7ue/XSYrl377Hn7tqlh5969dLDakfz1Ve6nRkz9A0xJkYPmdWyf78Wt6uv1jfKykotdOecU3/jfOkl3caZZza+Qefmai+lKdLTtaeXlNT0Z1hcrL0z0HY9/7y+9tG4XCLDhumh1nvu0fUffbT5z7IhbrfIkSPHr1M7J3nttfXzTA2HMY9HrbBfeaX2FG02qfMcExJE/v73xksTysvrvVXQyyJOEyNOPiRO9yy7R0L/FFo3otFwWNtwYqqq8mTv3kdlzZoQWb06UPbt+6O4XKc5IW5oGS+8oL0RPz895NWSifuWMGOG1A017mnigePJJ3W53S7Su7ccM9zkcmmv6GQj91yupgWnluRkPT9VUHD8dv797/ob+uzZrb/26Omn69u/+eaWt3/ggB7aS0rSXt+DD2pPb9s27d02hdst8sorWoxbAV8Tpy6dIeLa969lW/Y2Lk/fxfz5OqeoD27f5HUqKw+TlnYveXkfYrcPpnfv3xITc13bp0Pq6mzcqLNlDBjQem1mZ+s9ue69t+kcXtXV8OabOinv/v0QG6uzenSUL44I3HabXhP39NNtY9czz+h1cq+/DjZb67ffRvhahoguLU7nvX4e/n7+ON5P5uBB2LKlVZrtsuTlfcrevQ9TVraDwMBEEhIeIC7uNiwWu7dNMxi6PL4mTl06Q0RmSSZxwXGkpUH//t62xveJjp7CmDHbSEpaQkBAd/bsuYdvvunFvn2PU1WV623zDAaDD9FlxUlEyHRmEmvvzt69RpxaC6X8iI6ewsiRaxkx4ivCwiawb99cvvmmJ7t2/Qync6u3TTQYDD5Am4mTUmqBUipHKZV6gnpjlFIupdQ1bWVLU5RUlVBWXUZgdRw1NUacWhulFOHh5zJ06FLGjNlBXNyt5OS8Q0rKcFJTrzYiZTAYjktbek5vAE3sWVCPUsoCPIXeFrhdyXJmAeAujgOMOLUlDscgBgz4BxMmHCQx8XEKCpI9IjWNwsL/4WvzngaDoe1pM3ESkTXAkRNUuwf4EMhpKzuaI7MkE4CyHC1OrRnwZGgaqzWSxMTfMX78D/Tu/X8UFq5i8+bz2LhxDIcPv0J1dYG3TTQYDB0Er805KaXigauBl1tQd5ZSKkUplVJTU9Mq1890anE6cqA7ISE6ItbQPlitEfTp83smTDjIgAEv43aXs3v3LNau7U5q6jWUlHznbRMNBoOX8WZAxDxgjoi4TlRRROaLyFkicpa/f+usnan1nLL2xNG/f8dZptGVsFgc9Ojxc8aMSWX06BTi4++ksPC/bNw4ih07ZlJenu5tEw0Gg5fw5irJs4B3lFaFaODHSqkaEfmkPS6e5czCZrGxb2cEY7vYBoMdDaUUISGjCQkZTe/ej3Hw4FNkZMwjJ2cRDsdQIiN/TLduNxAcPNzbphoMhnbCa56TiPQRkUQRSQQ+AO5sL2ECPazXPbg7Bw8o+vZtr6saToTVGk7fvn9i7Ng0+vZ9Gqs1moyMZ0lJGcHmzReSl7cUt7t1hnYNBkPHpc08J6XUYmAiEK2UygAeA6wAInLCeaa2JtOZSaStO/troGdPb1tjOJrAwAR69XqQXr0epLq6gMzMVzh06O+kpk7B3z+S6OgpxMRcT2TkZSgzJmswdDraTJxE5IaTqHtLW9nRHJklmUT76fjxhIT2vrrhZLBaI+jV6yESEu4nP//f5OV9RG7ux2RlvYHDMYzevR8lJmYaemWCwWDoDHTZzJxZziwSgs4HjDj5Cn5+VmJiriIm5irc7ipyct5l//4n2bHjOqzWbkRGXkZk5CQiIydhtUZ421yDwXAadElxqnJVkV+ej0X0GicjTr6Hn18A3bv/hG7dbiQv7xNycz8kP//fZGe/iVL+hIX9iJiYacTG3ojVGu5tcw0Gw0nSJcWpNjtETVF3bDaIjvayQYZTRikLMTHTiYmZjoiL4uIN5OcvIS/vE9LS7iI9/dfExt5Ajx53EBIy1sxPGQw+QpcUp9o1ThW5cSQkmDVOnQWlLISFjScsbDx9+/6JkpJNHD78D7Kz3yYr6zUCA/sQGzuDbt1uwuEY4m1zDQbDceiSWclrPafiw3FmSK8TExIyijPPfIWzzz7MmWe+TlBQfw4c+AsbNiSRkjKagwfnUVWV520zDQZDE3RNz8mTuih/XxxDRnrZGEOb4+8fRlzcLcTF3UJVVTY5Oe+QlfUW6en3s3fvHKKjryY6egoBAd2wWqOx2wfj52f1ttkGQ5ema4pTSSYKRVZ6LAlXetsaQ3sSENCNhITZJCTMxulMJTPzVbKz3yI39926OjZbT3r2fIC4uNuxWHxm41CDoVPRNcXJmUlUUAx5lf5mWK8LExycRP/+8zjjjKcoL99DdXU+lZUHOXz4n+zZcx/79j3u8aquIiLiYiyWIG+bbDB0GbqkOKUdSaO7rQ95mDByA/j52RoFSHTrdhNFRV9z6NCL5OZ+QFbWApSyERo6lrCw8wkPP5/Q0LPx9w/2otUGQ+emy4mTiLAtexujgq4mFSNOhqYJCzuHsLBzcLurKCxM5siRFRQVreHAgT9z4MCTKOVPSMgYunW7iW7dZuLvH+Ztkw2GTkWXE6fs0mzyy/MJ9UsCTF49w/Hx8wvwZJ64DICaGifFxWspLFxFfv4y0tLuJj39IaKjryYkZCR2+xBCQ8ditUZ62XKDwbfpcuKUmpMKgLVgKFYrxMR42SCDT+HvH0xk5KVERl5K375/pLg4hcOHXyY//zNychZ5alkID/8R0dFXERl5GUFB/c3iX4PhJOly4rQtexsANRlDiY8Hvy650svQWoSGnkVo6KsAVFfnU1qaypEjX5CX9wl79twLQEBAHOHhEwkPv4Dw8AsICjrDiJXBcAKUiHjbhpPC4XBIaWlpo2PV1dVkZGRQUVFxwvPzy/IpqykjoLwnItC9e1tZ6hsEBgaSkJCA1WrW9bQ2ZWV7KCz8L4WFyRQUJFNdnQ1AYGBfYmOvIybmWoKDRxqhMrQLSqkyETnu2gil1CTgOcACvCoifz6q/CZgjuetE/iliGxpE3s7gzj98MMPhISEEBUVdcIv+s7cnfgpP6oyz8ThoEtvNCjeHnmCAAATtElEQVQi5OfnU1JSQp8+fbxtTqdGRCgr+57CwmTy8pZQUPAl4MJqjfVE/51DcPAwHI4kAgJivW2uoRNyInFSes+Z3cAlQAawAbhBRHY0qHM2sFNECpRSlwNzRWRcW9jbKYb1KioqSExMPKEwiQjlNeVE26NxVkF4F09WrZQiKiqK3Nxcb5vS6VFK4XAMxOEYSHz8L6muzicvbwmFhasoKvqK3NwP6urabD2JirqCqKgrCQs7F3//EC9abuhCjAX2iMheAKXUO8BUoE6cRGRtg/rfAm0W79wpxAlo0dBIpasSt7ix+QUhAgEB7WBYB8cMKXkHqzWKuLjbiIu7DYDKykxKS7dTVradwsI1ZGW9yeHD/wD0MGBw8AjCwy8gMnISdns/b5pu8F38lVIpDd7PF5H5Dd7HAwcbvM8AjucV/Qz4vBXta0SnEaeWUF5dDoC/6JX+RpwMHQWbLQ6bLY7IyItJSJiNy1VBUdEaSko24HRupaRkA3l5HwEQGHgGUVE/JipqMqGh55jFwIaWUiMiZx2nvKkn1SbnfZRSF6DF6dzWMKwpupY41WhxUm4tTq0VA1BYWMjbb7/NnXfeedLn/vjHP+btt98mvKuPMRoaYbEE1oWs11JWtocjR5Zz5MjnZGa+wqFDfwfAZuuFwzEYu30QdvtgQkJGmUALw6mQATRc+ZkAHD66klJqGPAqcLmI5LeVMV1LnKrLsVls1FRZgNbznAoLC3nppZeaFCeXy4XFYmn23GXLlrWOEYZOj93eD7v9bhIS7sblKqewcBVO5yZKS3dQVraDwsJVuN0VnrpDiIu7ndjY67DZenjZcoOPsAHor5TqAxwCZgA3NqyglOoFfAT8RER2t6UxnU6c7rsPNm9uuqy0ujt+yg8/F1RVQUgL55lHjIB585ov/81vfkN6ejojRozgkksuYfLkyTz++OPExcWxefNmduzYwVVXXcXBgwepqKhg9uzZzJo1C4DExERSUlJwOp1cfvnlnHvuuaxdu5b4+HiWLFlCUFDjZKNLly7liSeeoKqqiqioKBYtWkS3bt1wOp3cc889pKSkoJTiscceY/r06SxfvpxHHnkEl8tFdHQ0K1eubFmnDR0aiyWIqKjLiYq6vO6YiJuKiv0UFHxJZuarpKffT3r6/dhsvQgNHY/N1gOLJZSAgFgiIi7Bbh/gxR4YOhoiUqOUuhv4DzqUfIGIbFdK/cJT/jLwOyAKeMnjmZ9oqPCU6RSh5Dt37mTQoEHA8cRJKKlyEmAJQKptuFzgaOFuCCcSp3379nHFFVeQmqqzT6xatYrJkyeTmppaF6J95MgRIiMjKS8vZ8yYMaxevZqoqKhG4tSvXz9SUlIYMWIE1113HVOmTGHmzJmNrlVQUEB4eDhKKV599VV27tzJs88+y5w5c6isrGSex9CCggJqamoYNWoUa9asoU+fPnU2HE3Dz8/QeXA6UykoWEFx8TeUlKRQXZ2Hy1VSVx4U1I/w8AsJDh6OwzGM0NAx+PnZvGixoS1pyTqnjkSn85yaE5Gy6nJ25H5P34i+5OzXX8CBA9vOjrFjxzZaO/T888/z8ccfA3Dw4EHS0tKIiopqdE6fPn0YMWIEAKNHj2bfvn3HtJuRkcH1119PZmYmVVVVddf48ssveeedd+rqRUREsHTpUs4///y6Ok0Jk6HzEhycRHBwEnB/3bFa7+rIkc/Jz/+M3Nz3yMzUAVsWSxjR0VcRE3MNoaHjCQiI9pLlBkMnFKfmqI3UC/IPorISwto4ibSjgVu2atUqvvzyS7755hvsdjsTJ05sMpuFzVb/1GqxWCgvLz+mzj333MOvfvUrpkyZwqpVq5g7dy6g13AdPQHe1DFD10YpP4KC+hAffyfx8XciIlRWZuB0biI392Py8j4hO3shoAMtgoNHEBw8nODg4djtQwgKOsPsEmxoF7qMOIUHhjMweiBWZaO6GmytOHoREhJCSUlJs+VFRUVERERgt9vZtWsX33777Slfq6ioiPj4eAAWLlxYd/zSSy/lhRdeaDSsN2HCBO666y5++OGH4w7rGbouSikCA3sSGNiT6OipuN2VFBX9j5KSTTidm3A6N5Of/xng9tS3EhTUH7v9TIKCBuBwDCEs7BwCA/uYByFDq9JlxMniZyE4IJiyMv2+NcUpKiqKc845h6SkJC6//HImT57cqHzSpEm8/PLLDBs2jDPPPJPx48ef8rXmzp3LtddeS3x8POPHj+eHH34A4NFHH+Wuu+4iKSkJi8XCY489xrRp05g/fz7Tpk3D7XYTGxvLihUrTquvhs6Nn5+NiIiLiIi4qO6Yy1XuWSC8g7KynZSW7qSsbBf5+Z8hUg1AQEAPwsLOJjR0AqGhE3A4hpr1V4bTos0CIpRSC4ArgBwRSWqi/JQSCJ4oIOJEFBRAejoMHgx2e4tO6fSYgAjDqeB211BWtpOioq8pKvqK4uK1VFTsqyu32XoRGNgHEERc2GwJREZeQkTEJQQG9vKa3V0VExBRzxvAC8CbzZT/APyoQQLB+Rw/VUarUDvV05qek8HQFfHz8yc4eCjBwUOJj/8FAJWVWZSUrKO0dDulpduprDwI+OHnZ6OoaA25ue8CYLMlEBIypsFrNFZrhBd7Y+hotJk4icgapVTiccrbLYFgQyorwd8fjrMu1mAwnCI2W3dstqlER089pkxnZt9BQcFKiovXUVKynry8j+vKAwMTcTiScDiG4nAMIzh4OEFB/fHz6zKzD4YGdJS/+nETCCqlZgGzAAJOM61DZaXxmgwGb6Azsw/B4RhSd6y6uoCSko2eHIJbPJs1LkekBgA/v0CCggZgtw/E4RjiWZM1nMDA3iYAo5PjdXFqSQJBT+bc+aDnnE7nepWVLc8MYTAY2harNYLIyIuJjLy47pjbXUVZ2U6czi04nVspK9tJSUkKubnvU5uH1GqNISzsXEJDz8ZuH0hQUF8CA/tgsQQ1cyWDr+FVcWqvBIK1uN06bZHxnAyGjoufX0Dd2qqG1NQ4KS1NxencTHHxNxQV/a/RsCDoqMGgoH6eLUbOJyzsfAICYtrTfEMr4TVxas8EgrVUVuqfRpwMBt/D3z+YsLDxhIWNrwvAqKrKpbw8nYqKvZSXp3teezxZ258HdJqmkJBxhISchd3en6CgfgQG9sHPz+yZ05FpM3FSSi0GJgLRSqkM4DHACu2fQLCWjiROwcHBOJ1Ob5thMPg0AQExBATEEBbWeO2g211FSUkKhYVrKClZR2Hhf8nJWdSghsJmSyAo6IwGc1pJhIefb/ILdhDaMlrvhhOU3w7c3lbXb4raMPLAwPa8qsFgaG/8/AIICzubsLCz645VVeV4PKs0ysv31nlbubkfUlOjZxUsljBiYq4mJGQsbnc5bnc5Vms3HA69V5YJd28/vB4Q0drct/w+Nmc1vWdGRQXU1EBw6sm1OaL7COZNaj4t+Zw5c+jdu3fdfk5z584lJCSEn//850ydOpWCggKqq6t54oknmDr12BDbhjS3tUZTW180t02GwWA4loCAWAICYgkLm3BMWVVVHiUl68jJeY/c3I/IynqjyTZstt6EhIzEbh+CzdaDgIDuBAePJCioT5P1DadOpxOn4yECfn6t3+6MGTO477776sTpvffeY/ny5QQGBvLxxx8TGhpKXl4e48ePZ8qUKccNgV2wYEGjrTWmT5+O2+3mjjvuaLT1BcAf/vAHwsLC2LZtG6Dz6RkMhpMnICCaqKjJREVNxu2upLo6H4vFgVI2qqoOe9I2bcfp/I6Skk3k5X1Kbb5BgKCg/kREXFonXEFBZ+DvH2qGCE+DTidOx/Nwtm3Tezj17du61xw5ciQ5OTkcPnyY3NxcIiIi6NWrF9XV1TzyyCOsWbMGPz8/Dh06RHZ2Nt27d2+2raa21sjNzW1y64umtskwGAynh5+frdHuwUFBfQkK6ktUVH3OTLe7hurqPKqqDlFU9DVHjnxBVtYbHD78YqO2lLJis/UiJGQ0ISGjcDiG4XAkYbMlmHVaJ6DTiVNzuN06IKKtknJfc801fPDBB2RlZTFjxgwAFi1aRG5uLhs3bsRqtZKYmNjkVhm1NLe1RnNbX5gtMQwG7+Dn5+/JhtGdkJDRJCTci4iLiop9lJZup6JiHy6Xk5qaYsrL91BSsoHc3PfqzrdYwggOHorDMdzzMwm7fQhWa7gXe9Wx6DLiVFWlf7ZVpN6MGTO44447yMvLY/Xq1YDe3iI2Nhar1UpycjL79+8/bhvNba3R3NYXTW2TYbwng8E7KGXxRP+d0WR5dXWBJ+dgKqWlW3E6t5Kd/SaHD9dvtxMQEIfdPgi7fSA2WwI2Ww9PWqehWK1da7ubLiNObR1GPmTIEEpKSoiPjycuLg6Am266iSuvvJKzzjqLESNGMPAEW+82t7VGTExMk1tfNLdNhsFg6HhYrRGEh59LeHh9Mhy92eMBj2ClerYj2UlOztvU1BQ2Oj8gII6ePR+gZ88H2tt0r9BmW2a0Fae6ZYbTCVlZ0Ls3WM1Gno0wW2YYDB0Pl6uUysrDlJene4RrG5GRk+jW7birdJrFbJnRQQkOhn79vG2FwWAwtAyLxYHd3h+7vT9RUZO8bU670waB1QaDwWAwnB6dRpx8bXiyo2A+N4PB0BHpFOIUGBhIfn6+udGeJCJCfn4+gSafk8Fg6GB0ijmnhIQEMjIyyM3N9bYpPkdgYCAJCe2yCbHBYDC0mE4RrWcwGAyG4+Nr0XqdYljPYDAYDJ0LI04Gg8Fg6HAYcTIYDAZDh8Pn5pyUUm6g/BRP9wdqWtGcjoLpl29h+uVbdJZ+BYmIzzgkPidOp4NSKqWtt4L3BqZfvoXpl2/RWfvV0fEZFTUYDAZD18GIk8FgMBg6HF1NnOZ724A2wvTLtzD98i06a786NF1qzslgMBgMvkFX85wMBoPB4AMYcTIYDAZDh6PLiJNSapJS6nul1B6l1G+8bc+popTqqZRKVkrtVEptV0rN9hyPVEqtUEqleX5GeNvWk0UpZVFKfaeU+szzvjP0KVwp9YFSapfnbzahk/Trfs//X6pSarFSKtAX+6WUWqCUylFKpTY41mw/lFIPe+4h3yulLvOO1V2DLiFOSikL8CJwOTAYuEEpNdi7Vp0yNcADIjIIGA/c5enLb4CVItIfWOl572vMBnY2eN8Z+vQcsFxEBgLD0f3z6X4ppeKBe4GzRCQJsAAz8M1+vQEcvc1sk/3wfM9mAEM857zkubcY2oAuIU7AWGCPiOwVkSrgHWCql206JUQkU0Q2eX4vQd/s4tH9WeipthC4yjsWnhpKqQRgMvBqg8O+3qdQ4HzgNQARqRKRQny8Xx78gSCllD9gBw7jg/0SkTXAkaMON9ePqcA7IlIpIj8Ae9D3FkMb0FXEKR442OB9hueYT6OUSgRGAuuAbiKSCVrAgFjvWXZKzAMeAtwNjvl6n/oCucDrnuHKV5VSDny8XyJyCHgGOABkAkUi8gU+3q8GNNePTnkf6ah0FXFSTRzz6Rh6pVQw8CFwn4gUe9ue00EpdQWQIyIbvW1LK+MPjAL+ISIjgVJ8Y6jruHjmYKYCfYAegEMpNdO7VrULne4+0pHpKuKUAfRs8D4BPQzhkyilrGhhWiQiH3kOZyul4jzlcUCOt+w7Bc4Bpiil9qGHXC9USv0L3+4T6P+7DBFZ53n/AVqsfL1fFwM/iEiuiFQDHwFn4/v9qqW5fnSq+0hHp6uI0wagv1Kqj1IqAD2p+amXbTollFIKPYexU0T+2qDoU+Cnnt9/Cixpb9tOFRF5WEQSRCQR/bf5r4jMxIf7BCAiWcBBpdSZnkMXATvw8X6hh/PGK6Xsnv/Hi9Bzn77er1qa68enwAyllE0p1QfoD6z3gn1dgi6TIUIp9WP0vIYFWCAiT3rZpFNCKXUu8BWwjfr5mUfQ807vAb3QN49rReToid4Oj1JqIvCgiFyhlIrCx/uklBqBDvIIAPYCt6IfCn29X48D16OjR78DbgeC8bF+KaUWAxOBaCAbeAz4hGb6oZT6LXAbut/3icjnXjC7S9BlxMlgMBgMvkNXGdYzGAwGgw9hxMlgMBgMHQ4jTgaDwWDocBhxMhgMBkOHw4iTwWAwGDocRpwMhnZEKTWxNuu6wWBoHiNOBoPBYOhwGHEyGJpAKTVTKbVeKbVZKfVPz15TTqXUs0qpTUqplUqpGE/dEUqpb5VSW5VSH9fu/6OU6qeU+lIptcVzzhme5oMb7PG0yJNlwWAwNMCIk8FwFEqpQejsB+eIyAjABdwEOIBNIjIKWI3OJgDwJjBHRIahM3fUHl8EvCgiw9G55zI9x0cC96H3FuuLzi1oMBga4O9tAwyGDshFwGhgg8epCUIn/3QD73rq/Av4SCkVBoSLyGrP8YXA+0qpECBeRD4GEJEKAE9760Ukw/N+M5AI/K/tu2Uw+A5GnAyGY1HAQhF5uNFBpf7vqHrHy/11vKG6yga/uzDfQ4PhGMywnsFwLCuBa5RSsQBKqUilVG/09+UaT50bgf+JSBFQoJQ6z3P8J8Bqzx5bGUqpqzxt2JRS9nbthcHgw5gnNoPhKERkh1LqUeALpZQfUA3chd4scIhSaiNQhJ6XAr2twsse8anNPA5aqP6plPq9p41r27EbBoNPY7KSGwwtRCnlFJFgb9thMHQFzLCewWAwGDocxnMyGAwGQ4fDeE4Gg8Fg6HAYcTIYDAZDh8OIk8FgMBg6HEacDAaDwdDhMOJkMBgMhg7H/wNa/q0q8LUmKgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4511 - acc: 0.4437\n",
      "\n",
      "loss : 1.4511463642120361\n",
      "accuray : 0.44369998574256897\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "print('')\n",
    "print('loss : ' + str(loss_and_metrics[0]))\n",
    "print('accuray : ' + str(loss_and_metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EarlyStopping\n",
    "# callback function: 사용자가 설정한 환경이 되었을때 시스템에 의해 자동으로 호출되는 함수\n",
    "# monitor: 관찰항목(val loss, val acc)\n",
    "# min_delta: 개선되고 있다고 판단하기 위한 최소 변화량\n",
    "#            (변화량이 min_delta보다 작으면 개선이 안된 것으로 판단)\n",
    "# patience: 개선이 없다고 해서 바로 종료하는 게 아니라 몇 epochs동안 참을 수 있니(10이면 epochs 10까지 참아줌.)\n",
    "# mode: 개선이 없다고 판단하기 위한 기준,\n",
    "#       ex) 관찰항목이 val_loss인 경우, 감소되는 것이 멈출때 트레이닝 종료. → mode = 'min'\n",
    "#       ex) 관찰항목이 val_acc인 경우, mode = 'max'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 1.0940 - accuracy: 0.7413 - val_loss: 0.6294 - val_accuracy: 0.8448\n",
      "Epoch 2/5\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 0.5028 - accuracy: 0.8694 - val_loss: 0.4696 - val_accuracy: 0.8751\n",
      "Epoch 3/5\n",
      "563/563 [==============================] - 2s 4ms/step - loss: 0.4057 - accuracy: 0.8898 - val_loss: 0.4069 - val_accuracy: 0.8883\n",
      "Epoch 4/5\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 0.3608 - accuracy: 0.8995 - val_loss: 0.3783 - val_accuracy: 0.8946\n",
      "Epoch 5/5\n",
      "563/563 [==============================] - 2s 3ms/step - loss: 0.3341 - accuracy: 0.9060 - val_loss: 0.3536 - val_accuracy: 0.9010\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3258 - accuracy: 0.9096\n",
      "\n",
      "loss_and_metrics : [0.3257860243320465, 0.909600019454956]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "\n",
    "# 1. 데이터셋 생성하기\n",
    "# 훈련셋과 시험셋 불러오기\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 데이터셋 전처리\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# 원핫인코딩 (one-hot encoding) 처리\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# 훈련셋과 검증셋 분리\n",
    "x_val = x_train[:42000] # 훈련셋의 30%를 검증셋으로 사용\n",
    "x_train = x_train[42000:]\n",
    "y_val = y_train[:42000] # 훈련셋의 30%를 검증셋으로 사용\n",
    "y_train = y_train[42000:]\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정 설정하기\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. 모델 학습시키기\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32,validation_data=(x_val,y_val))\n",
    "          \n",
    "# 5. 모델 평가하기\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)\n",
    "print('')\n",
    "print('loss_and_metrics : ' + str(loss_and_metrics))\n",
    "\n",
    "# 6. 모델 사용하기\n",
    "xhat_idx = np.random.choice(x_test.shape[0], 5)\n",
    "xhat = x_test[xhat_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장: weight, bias 저장됨!!(Param)\n",
    "# pre-trained model은 이거와 동일함!!\n",
    "model.save(\"mymnist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "xhat_idx = np.random.choice(x_test.shape[0], 5)\n",
    "xhat = x_test[xhat_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(\"mymnist.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-56-89fc8507c77f>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "yhat = loaded_model.predict_classes(xhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN을 이용한 수열 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, SimpleRNN\n",
    "import numpy as np\n",
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0.0,0.1,0.2,0.3] → 그 다음값은 뭘까? 0.4 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([SimpleRNN(units = 1,\n",
    "                             activation = 'tanh',\n",
    "                             return_sequences = False,\n",
    "                             return_state = True)]) # 출력 1개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. ]\n",
      "  [0.1]\n",
      "  [0.2]\n",
      "  [0.3]]\n",
      "\n",
      " [[0.1]\n",
      "  [0.2]\n",
      "  [0.3]\n",
      "  [0.4]]\n",
      "\n",
      " [[0.2]\n",
      "  [0.3]\n",
      "  [0.4]\n",
      "  [0.5]]\n",
      "\n",
      " [[0.3]\n",
      "  [0.4]\n",
      "  [0.5]\n",
      "  [0.6]]\n",
      "\n",
      " [[0.4]\n",
      "  [0.5]\n",
      "  [0.6]\n",
      "  [0.7]]\n",
      "\n",
      " [[0.5]\n",
      "  [0.6]\n",
      "  [0.7]\n",
      "  [0.8]]]\n",
      "[0.4 0.5 0.6 0.7 0.8 0.9]\n"
     ]
    }
   ],
   "source": [
    "X = [] \n",
    "Y = [] \n",
    "\n",
    "for i in range(6): \n",
    "    lst = list(range(i,i+4)) \n",
    "    X.append(list(map(lambda c: [c/10], lst))) \n",
    "    Y.append((i+4)/10) \n",
    "X = np.array(X) \n",
    "Y = np.array(Y) \n",
    "\n",
    "print(X)  #6,4,1\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 4, 1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # 6건의 data, 4행 1열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([SimpleRNN(units = 30, # value in hidden layer: 10\n",
    "                      return_sequences = False,\n",
    "                      input_shape=[4,1]),\n",
    "           Dense(1,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss = 'mse',) # 연속형 값 출력: mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.9266e-06\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.9020e-06\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.8773e-06\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.8527e-06\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.8283e-06\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.8042e-06\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.7801e-06\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.7563e-06\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.7324e-06\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7089e-06\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.6855e-06\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.6623e-06\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.6389e-06\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.6162e-06\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.5935e-06\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.5705e-06\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.5481e-06\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.5257e-06\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.5038e-06\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.4814e-06\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.4596e-06\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.4376e-06\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.4163e-06\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.3947e-06\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.3732e-06\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.3521e-06\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.3311e-06\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.3101e-06\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.2893e-06\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.2683e-06\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.2483e-06\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.2278e-06\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.2075e-06\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.1874e-06\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.1676e-06\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.1476e-06\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.1282e-06\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.1084e-06\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.0889e-06\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.0697e-06\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.0505e-06\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.0315e-06\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 3.0127e-06\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.9939e-06\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.9750e-06\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.9568e-06\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.9384e-06\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.9201e-06\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.9020e-06\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.8841e-06\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.8660e-06\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.8483e-06\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.8304e-06\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.8129e-06\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.7956e-06\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.7784e-06\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.7615e-06\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.7442e-06\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.7274e-06\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.7104e-06\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.6939e-06\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.6772e-06\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.6606e-06\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.6443e-06\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.6280e-06\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.6120e-06\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.5962e-06\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.5804e-06\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.5647e-06\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.5487e-06\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.5333e-06\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.5178e-06\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.5025e-06\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.4873e-06\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.4724e-06\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.4572e-06\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4425e-06\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.4276e-06\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.4126e-06\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.3983e-06\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.3841e-06\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.3695e-06\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.3551e-06\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.3411e-06\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.3271e-06\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.3130e-06\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.2992e-06\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2856e-06\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.2719e-06\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.2581e-06\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.2449e-06\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.2314e-06\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2183e-06\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.2050e-06\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.1920e-06\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.1789e-06\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1659e-06\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.1533e-06\n",
      "Epoch 99/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 2.1406e-06\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.1280e-06\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.1156e-06\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1029e-06\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.0908e-06\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.0785e-06\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0664e-06\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.0544e-06\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.0423e-06\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0307e-06\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.0187e-06\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 2.0070e-06\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.9954e-06\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.9839e-06\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.9725e-06\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9612e-06\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9497e-06\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.9387e-06\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.9276e-06\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.9166e-06\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.9057e-06\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8947e-06\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8840e-06\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8732e-06\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.8629e-06\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.8522e-06\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.8417e-06\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.8314e-06\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.8211e-06\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.8110e-06\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.8006e-06\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.7907e-06\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7807e-06\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.7708e-06\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.7611e-06\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.7513e-06\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7416e-06\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.7319e-06\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.7224e-06\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.7130e-06\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.7037e-06\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6942e-06\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.6851e-06\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.6760e-06\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.6669e-06\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.6577e-06\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.6487e-06\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.6399e-06\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.6312e-06\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.6223e-06\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.6137e-06\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6051e-06\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5965e-06\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5881e-06\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5796e-06\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5712e-06\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5630e-06\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5549e-06\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5467e-06\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5385e-06\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5305e-06\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5225e-06\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5145e-06\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.5068e-06\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4990e-06\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4913e-06\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4837e-06\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4761e-06\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4684e-06\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4609e-06\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4537e-06\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4463e-06\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4389e-06\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4316e-06\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4246e-06\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4172e-06\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4104e-06\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4033e-06\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3963e-06\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3895e-06\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3825e-06\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3757e-06\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3691e-06\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3625e-06\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3558e-06\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3493e-06\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3427e-06\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3363e-06\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3299e-06\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3234e-06\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3174e-06\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3110e-06\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3046e-06\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2985e-06\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2925e-06\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2863e-06\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2804e-06\n",
      "Epoch 196/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 1.2744e-06\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2684e-06\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2625e-06\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2568e-06\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2511e-06\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2453e-06\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2395e-06\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2340e-06\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2284e-06\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2229e-06\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2173e-06\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2120e-06\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2065e-06\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2011e-06\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1960e-06\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1906e-06\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1853e-06\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1803e-06\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1752e-06\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1699e-06\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1649e-06\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1599e-06\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1548e-06\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1500e-06\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1451e-06\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1403e-06\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1354e-06\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1307e-06\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1260e-06\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1213e-06\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1167e-06\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1120e-06\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1075e-06\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1028e-06\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0984e-06\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0939e-06\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0895e-06\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0851e-06\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0808e-06\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0765e-06\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0723e-06\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0680e-06\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0639e-06\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0597e-06\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0556e-06\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0513e-06\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0474e-06\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0433e-06\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0394e-06\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0354e-06\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0316e-06\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0277e-06\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0238e-06\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0200e-06\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0161e-06\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0124e-06\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0086e-06\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0048e-06\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.0014e-06\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.9772e-07\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.9407e-07\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.9031e-07\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.8708e-07\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.8348e-07\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.7981e-07\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.7652e-07\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.7302e-07\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.6967e-07\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.6631e-07\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.6300e-07\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.5964e-07\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.5637e-07\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.5318e-07\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.4981e-07\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.4667e-07\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.4351e-07\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.4052e-07\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.3732e-07\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.3428e-07\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.3110e-07\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.2819e-07\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.2515e-07\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.2214e-07\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.1921e-07\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.1619e-07\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.1336e-07\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.1063e-07\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.0766e-07\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.0491e-07\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9.0199e-07\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.9912e-07\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.9646e-07\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.9373e-07\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.9102e-07\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.8837e-07\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.8566e-07\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.8307e-07\n",
      "Epoch 293/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 8.8050e-07\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.7781e-07\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.7537e-07\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.7283e-07\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.7026e-07\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.6787e-07\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.6526e-07\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.6272e-07\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.6033e-07\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.5804e-07\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.5556e-07\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.5325e-07\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.5091e-07\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.4868e-07\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.4622e-07\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.4396e-07\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.4168e-07\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.3947e-07\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.3723e-07\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.3513e-07\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.3278e-07\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.3066e-07\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.2845e-07\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.2641e-07\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.2415e-07\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.2207e-07\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.2006e-07\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.1803e-07\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.1608e-07\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.1390e-07\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.1204e-07\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.1001e-07\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.0808e-07\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.0605e-07\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.0413e-07\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.0221e-07\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 8.0035e-07\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.9842e-07\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.9659e-07\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.9476e-07\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.9290e-07\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.9112e-07\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.8923e-07\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.8742e-07\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.8567e-07\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.8399e-07\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.8222e-07\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.8051e-07\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.7880e-07\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.7716e-07\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.7546e-07\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.7370e-07\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.7207e-07\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.7038e-07\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.6875e-07\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.6725e-07\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.6569e-07\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.6409e-07\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.6254e-07\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.6092e-07\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.5948e-07\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.5798e-07\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.5639e-07\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.5502e-07\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.5342e-07\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.5207e-07\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.5060e-07\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.4916e-07\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.4771e-07\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.4627e-07\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.4489e-07\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.4344e-07\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.4211e-07\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.4064e-07\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.3934e-07\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.3801e-07\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.3674e-07\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.3528e-07\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.3409e-07\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.3280e-07\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.3157e-07\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.3019e-07\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.2895e-07\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.2765e-07\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.2641e-07\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.2531e-07\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.2399e-07\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.2271e-07\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.2165e-07\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.2026e-07\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.1931e-07\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1810e-07\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.1696e-07\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.1569e-07\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1460e-07\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1346e-07\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.1244e-07\n",
      "Epoch 390/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 7.1142e-07\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1023e-07\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.0916e-07\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.0796e-07\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.0694e-07\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.0593e-07\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0491e-07\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0384e-07\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.0282e-07\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.0183e-07\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 7.0071e-07\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9979e-07\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9886e-07\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9778e-07\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9676e-07\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9590e-07\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9486e-07\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9397e-07\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9299e-07\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9220e-07\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9119e-07\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.9016e-07\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.8935e-07\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.8850e-07\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8755e-07\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.8657e-07\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.8566e-07\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.8480e-07\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.8392e-07\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.8315e-07\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.8220e-07\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.8150e-07\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.8059e-07\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.7984e-07\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7903e-07\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.7814e-07\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.7741e-07\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.7657e-07\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.7582e-07\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.7495e-07\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.7431e-07\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.7348e-07\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.7273e-07\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.7194e-07\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.7110e-07\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.7043e-07\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.6972e-07\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.6887e-07\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.6821e-07\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.6752e-07\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.6673e-07\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.6608e-07\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.6533e-07\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.6467e-07\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.6397e-07\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.6329e-07\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.6259e-07\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.6191e-07\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.6132e-07\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.6061e-07\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.6001e-07\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.5924e-07\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.5874e-07\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.5792e-07\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5729e-07\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.5668e-07\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.5611e-07\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.5551e-07\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.5492e-07\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.5422e-07\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.5366e-07\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5301e-07\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.5242e-07\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.5188e-07\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.5126e-07\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.5068e-07\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.5004e-07\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.4952e-07\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.4893e-07\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.4844e-07\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.4779e-07\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.4737e-07\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.4684e-07\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.4616e-07\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.4566e-07\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.4523e-07\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.4463e-07\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.4414e-07\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4358e-07\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.4301e-07\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.4247e-07\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.4192e-07\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.4156e-07\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.4093e-07\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.4043e-07\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.4003e-07\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3953e-07\n",
      "Epoch 487/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 6.3899e-07\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.3851e-07\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.3810e-07\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.3758e-07\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.3705e-07\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.3665e-07\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.3615e-07\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.3575e-07\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.3518e-07\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.3475e-07\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.3430e-07\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.3385e-07\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.3351e-07\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3291e-07\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.3257e-07\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.3212e-07\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.3163e-07\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.3123e-07\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3074e-07\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.3037e-07\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2997e-07\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.2950e-07\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2922e-07\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2878e-07\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2834e-07\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2788e-07\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2754e-07\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2714e-07\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2664e-07\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.2630e-07\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2591e-07\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2557e-07\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2514e-07\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2475e-07\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.2441e-07\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2401e-07\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2365e-07\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2321e-07\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2288e-07\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.2252e-07\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2211e-07\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2178e-07\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2144e-07\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2110e-07\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2070e-07\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.2030e-07\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1991e-07\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1968e-07\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1929e-07\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1895e-07\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1870e-07\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1820e-07\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.1796e-07\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1766e-07\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1726e-07\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1691e-07\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1668e-07\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1631e-07\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1600e-07\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1572e-07\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1535e-07\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1502e-07\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1462e-07\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1436e-07\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1405e-07\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1374e-07\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1340e-07\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1307e-07\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1285e-07\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1254e-07\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1226e-07\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1193e-07\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1166e-07\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1132e-07\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1099e-07\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1071e-07\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.1040e-07\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.1009e-07\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0986e-07\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0958e-07\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0921e-07\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0891e-07\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0875e-07\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0835e-07\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0812e-07\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0786e-07\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0755e-07\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0720e-07\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.0702e-07\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0684e-07\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0650e-07\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.0615e-07\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0601e-07\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0561e-07\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0544e-07\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0520e-07\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0482e-07\n",
      "Epoch 584/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 6.0462e-07\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 468us/step - loss: 6.0443e-07\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0403e-07\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0383e-07\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0355e-07\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0330e-07\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.0307e-07\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0278e-07\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 656us/step - loss: 6.0260e-07\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0238e-07\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0206e-07\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.0187e-07\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0159e-07\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0142e-07\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0108e-07\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0081e-07\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0056e-07\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 6.0041e-07\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.0011e-07\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9982e-07\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9969e-07\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9951e-07\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9914e-07\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9892e-07\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9870e-07\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9844e-07\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9818e-07\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9798e-07\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.9789e-07\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9752e-07\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9736e-07\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9703e-07\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9694e-07\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9665e-07\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9640e-07\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9614e-07\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.9600e-07\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9577e-07\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9553e-07\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9526e-07\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9505e-07\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9492e-07\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9462e-07\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9439e-07\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.9424e-07\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9404e-07\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9383e-07\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.9354e-07\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9331e-07\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9326e-07\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9297e-07\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9277e-07\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9249e-07\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9227e-07\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9213e-07\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9188e-07\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9163e-07\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.9130e-07\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9126e-07\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9100e-07\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9071e-07\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9058e-07\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9037e-07\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9026e-07\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.9010e-07\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8975e-07\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8970e-07\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8937e-07\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8925e-07\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8909e-07\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8881e-07\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8862e-07\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8844e-07\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8820e-07\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8808e-07\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8782e-07\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8769e-07\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8737e-07\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8727e-07\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8705e-07\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8683e-07\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8666e-07\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8646e-07\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8622e-07\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8605e-07\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8590e-07\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8570e-07\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8555e-07\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8539e-07\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8513e-07\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8495e-07\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8479e-07\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8459e-07\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8448e-07\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8423e-07\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8408e-07\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8385e-07\n",
      "Epoch 681/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 5.8362e-07\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8345e-07\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8317e-07\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8303e-07\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8285e-07\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8276e-07\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8252e-07\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8231e-07\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8216e-07\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8198e-07\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8182e-07\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8161e-07\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8150e-07\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8122e-07\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8095e-07\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8084e-07\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8069e-07\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8060e-07\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8025e-07\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.8011e-07\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7995e-07\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7978e-07\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7962e-07\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7944e-07\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7920e-07\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7910e-07\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7887e-07\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7871e-07\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7856e-07\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7840e-07\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7821e-07\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7801e-07\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7789e-07\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7763e-07\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7749e-07\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7727e-07\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7714e-07\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7697e-07\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7691e-07\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7653e-07\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7647e-07\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7622e-07\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7605e-07\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7593e-07\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7570e-07\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7563e-07\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7531e-07\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7533e-07\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7502e-07\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7492e-07\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7467e-07\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7460e-07\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7434e-07\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7427e-07\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7400e-07\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7393e-07\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7375e-07\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7350e-07\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7329e-07\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7319e-07\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7306e-07\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7291e-07\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7269e-07\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7250e-07\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7235e-07\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7215e-07\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7203e-07\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7180e-07\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7167e-07\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7150e-07\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7124e-07\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7116e-07\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7101e-07\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7082e-07\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7064e-07\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7047e-07\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7029e-07\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.7017e-07\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.7009e-07\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6985e-07\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6962e-07\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6951e-07\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6933e-07\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6907e-07\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6889e-07\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6876e-07\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6870e-07\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6848e-07\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6834e-07\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6813e-07\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6802e-07\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6778e-07\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6764e-07\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6746e-07\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6732e-07\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6720e-07\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6693e-07\n",
      "Epoch 778/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 5.6691e-07\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6667e-07\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6650e-07\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6630e-07\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6617e-07\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6604e-07\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6579e-07\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6566e-07\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6546e-07\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6539e-07\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6518e-07\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6502e-07\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6484e-07\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.6468e-07\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6448e-07\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6433e-07\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6418e-07\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6402e-07\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6391e-07\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6378e-07\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6353e-07\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6339e-07\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6324e-07\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6301e-07\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6288e-07\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6270e-07\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6261e-07\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6240e-07\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6231e-07\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6202e-07\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6194e-07\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6175e-07\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6164e-07\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6151e-07\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6127e-07\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6108e-07\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6096e-07\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6077e-07\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6069e-07\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6047e-07\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6027e-07\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.6011e-07\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5996e-07\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.5981e-07\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5964e-07\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5948e-07\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5930e-07\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5914e-07\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5902e-07\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5889e-07\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.5868e-07\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5846e-07\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5822e-07\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5824e-07\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5807e-07\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5782e-07\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5770e-07\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5754e-07\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5740e-07\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5724e-07\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5712e-07\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5693e-07\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5669e-07\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5650e-07\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5647e-07\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5623e-07\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.5607e-07\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5599e-07\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5580e-07\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5553e-07\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5545e-07\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5535e-07\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5514e-07\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.5500e-07\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5485e-07\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5457e-07\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5446e-07\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5430e-07\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5422e-07\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5400e-07\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5377e-07\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.5368e-07\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5349e-07\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5331e-07\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.5325e-07\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5295e-07\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.5291e-07\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5275e-07\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.5255e-07\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5237e-07\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5219e-07\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5204e-07\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5187e-07\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5173e-07\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5159e-07\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5141e-07\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5120e-07\n",
      "Epoch 875/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 5.5111e-07\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5093e-07\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5066e-07\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5055e-07\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5042e-07\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.5030e-07\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.5021e-07\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4996e-07\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4987e-07\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4966e-07\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.4951e-07\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4934e-07\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4914e-07\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4907e-07\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4885e-07\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.4871e-07\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4855e-07\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4837e-07\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4814e-07\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4804e-07\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4788e-07\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4771e-07\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.4765e-07\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4744e-07\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4731e-07\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4708e-07\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4695e-07\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4674e-07\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.4667e-07\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4647e-07\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4632e-07\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4608e-07\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4601e-07\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4587e-07\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.4570e-07\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.4545e-07\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.4525e-07\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4519e-07\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.4500e-07\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4481e-07\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4471e-07\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4445e-07\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4434e-07\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4417e-07\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4402e-07\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4391e-07\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4365e-07\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4354e-07\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4336e-07\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4326e-07\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4304e-07\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4295e-07\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4273e-07\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4252e-07\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.4238e-07\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4219e-07\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4211e-07\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4196e-07\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4175e-07\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4163e-07\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4144e-07\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4134e-07\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4107e-07\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4100e-07\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4088e-07\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4062e-07\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4042e-07\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4032e-07\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4010e-07\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.4004e-07\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3984e-07\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3968e-07\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3961e-07\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3936e-07\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3911e-07\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3899e-07\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3886e-07\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3874e-07\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3853e-07\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3847e-07\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3820e-07\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3810e-07\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3791e-07\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3779e-07\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3752e-07\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3752e-07\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3722e-07\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3707e-07\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3696e-07\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3681e-07\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3668e-07\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3649e-07\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3628e-07\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3609e-07\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3592e-07\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3578e-07\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3568e-07\n",
      "Epoch 972/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 0s/step - loss: 5.3557e-07\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3532e-07\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3523e-07\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3505e-07\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3487e-07\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3463e-07\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3457e-07\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3435e-07\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3427e-07\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3403e-07\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.3384e-07\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3372e-07\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3350e-07\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3345e-07\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3322e-07\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3311e-07\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3292e-07\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3273e-07\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3255e-07\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3241e-07\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3225e-07\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3204e-07\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3199e-07\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3174e-07\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3158e-07\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3150e-07\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3122e-07\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3115e-07\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 0s/step - loss: 5.3086e-07\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4004906 ],\n",
       "       [0.4993631 ],\n",
       "       [0.59938747],\n",
       "       [0.7004861 ],\n",
       "       [0.80111015],\n",
       "       [0.8991665 ]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9927621]], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[[0.6],[0.7],[0.8],[0.9]]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 기반 문장 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "text=\"\"\"인공지능을 공부하면서 코딩을 하고 있다\\n\n",
    "파이썬 코딩을 배우고 익혔다\\n\n",
    "딥러닝을 배우고 코딩을 하고 있다\\n\n",
    "파이썬 기반에서 판다스를 배우고 코딩을 했다\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능을 공부하면서 코딩을 하고 있다\n",
      "\n",
      "파이썬 코딩을 배우고 익혔다\n",
      "\n",
      "딥러닝을 배우고 코딩을 하고 있다\n",
      "\n",
      "파이썬 기반에서 판다스를 배우고 코딩을 했다\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "t.fit_on_texts([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['인공지능을 공부하면서 코딩을 하고 있다\\n\\n파이썬 코딩을 배우고 익혔다\\n\\n딥러닝을 배우고 코딩을 하고 있다\\n\\n파이썬 기반에서 판다스를 배우고 코딩을 했다\\n']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'코딩을': 1,\n",
       " '배우고': 2,\n",
       " '하고': 3,\n",
       " '있다': 4,\n",
       " '파이썬': 5,\n",
       " '인공지능을': 6,\n",
       " '공부하면서': 7,\n",
       " '익혔다': 8,\n",
       " '딥러닝을': 9,\n",
       " '기반에서': 10,\n",
       " '판다스를': 11,\n",
       " '했다': 12}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '코딩을',\n",
       " 2: '배우고',\n",
       " 3: '하고',\n",
       " 4: '있다',\n",
       " 5: '파이썬',\n",
       " 6: '인공지능을',\n",
       " 7: '공부하면서',\n",
       " 8: '익혔다',\n",
       " 9: '딥러닝을',\n",
       " 10: '기반에서',\n",
       " 11: '판다스를',\n",
       " 12: '했다'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('인공지능을', 1),\n",
       "             ('공부하면서', 1),\n",
       "             ('코딩을', 4),\n",
       "             ('하고', 2),\n",
       "             ('있다', 2),\n",
       "             ('파이썬', 2),\n",
       "             ('배우고', 3),\n",
       "             ('익혔다', 1),\n",
       "             ('딥러닝을', 1),\n",
       "             ('기반에서', 1),\n",
       "             ('판다스를', 1),\n",
       "             ('했다', 1)])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(t.word_index)+1\n",
    "# 실제 단어는 12개, index는 0번부터 11번까지. +1을 해서 0~13까지 쓰겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 크기 :  13\n"
     ]
    }
   ],
   "source": [
    "print(\"단어 크기 : \",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = list()\n",
    "for line in text.split('\\n'): \n",
    "    encoded = t.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 7],\n",
       " [6, 7, 1],\n",
       " [6, 7, 1, 3],\n",
       " [6, 7, 1, 3, 4],\n",
       " [5, 1],\n",
       " [5, 1, 2],\n",
       " [5, 1, 2, 8],\n",
       " [9, 2],\n",
       " [9, 2, 1],\n",
       " [9, 2, 1, 3],\n",
       " [9, 2, 1, 3, 4],\n",
       " [5, 10],\n",
       " [5, 10, 11],\n",
       " [5, 10, 11, 2],\n",
       " [5, 10, 11, 2, 1],\n",
       " [5, 10, 11, 2, 1, 12]]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences # 마지막 숫자가 y data! 나머지는 다 x data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(len(i) for i in sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pad_sequences(sequences, maxlen = max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequences[:,:-1]\n",
    "Y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(Y, num_classes=vocab_size) # 0번 제외, 1번~12번까지 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 5)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 13)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 갯수가 많으면 word2vec → 차원축소\n",
    "# 파이썬: [0000000...0000] : 1만 차원\n",
    "# keras에 Embedding → 저차원 공간에 단어 표시! 1만차원 → 5차원도 가능!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(Embedding(vocab_size,10,input_length=max_len-1)) # 13차원 → 10차원으로 embedding\n",
    "model.add(SimpleRNN(32)) # 출력 dim\n",
    "model.add(Dense(vocab_size,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3383 - acc: 0.8750\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3339 - acc: 0.8750\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3295 - acc: 0.8750\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3253 - acc: 0.8750\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3212 - acc: 0.8750\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3172 - acc: 0.8750\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3133 - acc: 0.8750\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3095 - acc: 0.8750\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3057 - acc: 0.8750\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.3021 - acc: 0.8750\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2985 - acc: 0.8750\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2950 - acc: 0.8750\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2916 - acc: 0.8750\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2883 - acc: 0.8750\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2851 - acc: 0.8750\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2819 - acc: 0.8750\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2788 - acc: 0.8750\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2758 - acc: 0.8750\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2728 - acc: 0.8750\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2699 - acc: 0.8750\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2671 - acc: 0.8750\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2643 - acc: 0.8750\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2616 - acc: 0.8750\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2589 - acc: 0.8750\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2563 - acc: 0.8750\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2538 - acc: 0.8750\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2513 - acc: 0.8750\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2489 - acc: 0.8750\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2465 - acc: 0.8750\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2442 - acc: 0.8750\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2419 - acc: 0.9375\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2396 - acc: 0.9375\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2374 - acc: 0.9375\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2353 - acc: 0.9375\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2331 - acc: 0.9375\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2311 - acc: 0.9375\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2290 - acc: 0.9375\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2270 - acc: 0.9375\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2250 - acc: 0.9375\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2231 - acc: 0.9375\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2212 - acc: 0.9375\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2193 - acc: 0.9375\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2175 - acc: 0.9375\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2157 - acc: 0.9375\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2139 - acc: 0.9375\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2122 - acc: 0.9375\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2105 - acc: 0.9375\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2088 - acc: 0.9375\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2071 - acc: 0.9375\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2054 - acc: 0.9375\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2038 - acc: 0.9375\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.2022 - acc: 0.9375\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2007 - acc: 0.9375\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1991 - acc: 0.9375\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1976 - acc: 0.9375\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1961 - acc: 0.9375\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1946 - acc: 0.9375\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1931 - acc: 0.9375\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1917 - acc: 0.9375\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1902 - acc: 0.9375\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1888 - acc: 0.9375\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1874 - acc: 0.9375\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1860 - acc: 0.9375\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1847 - acc: 0.9375\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1833 - acc: 0.9375\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1820 - acc: 0.9375\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1807 - acc: 0.9375\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1794 - acc: 0.9375\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1781 - acc: 0.9375\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1768 - acc: 0.9375\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1756 - acc: 0.9375\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1743 - acc: 0.9375\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1731 - acc: 0.9375\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1718 - acc: 0.9375\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1706 - acc: 0.9375\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1694 - acc: 0.9375\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1682 - acc: 0.9375\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1671 - acc: 0.9375\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1659 - acc: 0.9375\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1647 - acc: 0.9375\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1636 - acc: 0.9375\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1625 - acc: 0.9375\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1613 - acc: 0.9375\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1602 - acc: 0.9375\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1591 - acc: 0.9375\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1580 - acc: 0.9375\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1569 - acc: 0.9375\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1558 - acc: 0.9375\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1548 - acc: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1537 - acc: 0.9375\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1526 - acc: 0.9375\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1516 - acc: 0.9375\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1506 - acc: 0.9375\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1495 - acc: 0.9375\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1485 - acc: 0.9375\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1475 - acc: 0.9375\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1465 - acc: 0.9375\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1455 - acc: 0.9375\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1445 - acc: 0.9375\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1436 - acc: 0.9375\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1426 - acc: 0.9375\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1416 - acc: 0.9375\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1407 - acc: 0.9375\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1398 - acc: 0.9375\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1388 - acc: 0.9375\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1379 - acc: 0.9375\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1370 - acc: 0.9375\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1362 - acc: 0.9375\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1353 - acc: 0.9375\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1344 - acc: 0.9375\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1336 - acc: 0.9375\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1328 - acc: 0.9375\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1320 - acc: 0.9375\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1312 - acc: 0.9375\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1304 - acc: 0.9375\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1296 - acc: 0.9375\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1289 - acc: 0.9375\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1282 - acc: 0.9375\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1274 - acc: 0.9375\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1267 - acc: 0.9375\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1260 - acc: 0.9375\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1254 - acc: 0.9375\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1247 - acc: 0.9375\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1240 - acc: 0.9375\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1234 - acc: 0.9375\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1227 - acc: 0.9375\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1221 - acc: 0.9375\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1215 - acc: 0.9375\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1209 - acc: 0.9375\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1203 - acc: 0.9375\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1198 - acc: 0.9375\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1192 - acc: 0.9375\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1186 - acc: 0.9375\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1181 - acc: 0.9375\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1176 - acc: 0.9375\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1170 - acc: 0.9375\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1165 - acc: 0.9375\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1160 - acc: 0.9375\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1155 - acc: 0.9375\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1150 - acc: 0.9375\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1146 - acc: 0.9375\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1141 - acc: 0.9375\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1136 - acc: 0.9375\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1132 - acc: 0.9375\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1127 - acc: 0.9375\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1123 - acc: 0.9375\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1119 - acc: 0.9375\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1115 - acc: 0.9375\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1111 - acc: 0.9375\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1107 - acc: 0.9375\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1103 - acc: 0.9375\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1099 - acc: 0.9375\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1095 - acc: 0.9375\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1092 - acc: 0.9375\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1088 - acc: 0.9375\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1085 - acc: 0.9375\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1081 - acc: 0.9375\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1078 - acc: 0.9375\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1075 - acc: 0.9375\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1071 - acc: 0.9375\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1068 - acc: 0.9375\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1065 - acc: 0.9375\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1062 - acc: 0.9375\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1059 - acc: 0.9375\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1056 - acc: 0.9375\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1053 - acc: 0.9375\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1050 - acc: 0.9375\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1048 - acc: 0.9375\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1045 - acc: 0.9375\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1042 - acc: 0.9375\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1040 - acc: 0.9375\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1037 - acc: 0.9375\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1035 - acc: 0.9375\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1033 - acc: 0.9375\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1030 - acc: 0.9375\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1028 - acc: 0.9375\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1026 - acc: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1023 - acc: 0.9375\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1021 - acc: 0.9375\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1019 - acc: 0.9375\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 618us/step - loss: 0.1017 - acc: 0.9375\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1015 - acc: 0.9375\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1013 - acc: 0.9375\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1011 - acc: 0.9375\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1009 - acc: 0.9375\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1007 - acc: 0.9375\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1005 - acc: 0.9375\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1003 - acc: 0.9375\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1001 - acc: 0.9375\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.1000 - acc: 0.9375\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0998 - acc: 0.9375\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0996 - acc: 0.9375\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0995 - acc: 0.9375\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0993 - acc: 0.9375\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0991 - acc: 0.9375\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0990 - acc: 0.9375\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0988 - acc: 0.9375\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0987 - acc: 0.9375\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0985 - acc: 0.9375\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 0s/step - loss: 0.0984 - acc: 0.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26d0eb25388>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', \n",
    "             optimizer='adam',\n",
    "             metrics='acc')\n",
    "model.fit(X,y,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 7]\n"
     ]
    }
   ],
   "source": [
    "t.word_index\n",
    "print(t.texts_to_sequences([['인공지능을','공부하면서']])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 6]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequences([[6]],maxlen=5,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, tokenizer, current_word, n):\n",
    "    init_word=current_word # 문장의 시작단어 저장: '인공지능을\n",
    "    sentence = ''\n",
    "    for _ in range(n): # n번 반복\n",
    "        encoded = t.texts_to_sequences([current_word])[0] # 단어('인공지능을')의 인덱스\n",
    "        encoded = pad_sequences([encoded],maxlen=5,padding='pre') # array([[0,0,0,0,6]]) 패딩\n",
    "        result = model.predict_classes(encoded)\n",
    "        # 입력단어: encoded, 예측단어: result\n",
    "        for word, index in t.word_index.items():\n",
    "            if index == result:\n",
    "                break\n",
    "        current_word = current_word + \" \" + word\n",
    "        sentence = sentence + \" \" + word\n",
    "    sentence = init_word+sentence\n",
    "                \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파이썬 코딩을 배우고 익혔다 하고 있다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model,t,'파이썬',5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
